{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b298bc4a",
   "metadata": {
    "papermill": {
     "duration": 0.009169,
     "end_time": "2024-03-26T22:19:26.881103",
     "exception": false,
     "start_time": "2024-03-26T22:19:26.871934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Thicket Nsight Compute Reader: Thicket Tutorial\n",
    "\n",
    "Nsight Compute (NCU) is a performance profiler for NVIDIA GPUs. NCU report files do not have a calltree, but with the NVTX Caliper service we can forward Caliper annotations to NCU. By profiling the same executable with a calltree profiler like Caliper, we can map the NCU data to the calltree profile and create a Thicket object. \n",
    "\n",
    "In Section 6, we reproduce some of the analysis and visualizations from the paper:\n",
    "\n",
    "Olga Pearce, Jason Burmark, Rich Hornung, Befikir Bogale, Ian Lumsden, Michael McKinsey, Dewi Yokelson, David Boehme, Stephanie Brink, Michela Taufer, and Tom Scogland. “RAJA Performance Suite: Performance Portability Analysis with Caliper and Thicket”. SC-W 2024: Workshops of ACM/IEEE International Conference for High Performance Computing, Networking, Storage, and Analysis. Performance, Portability & Productivity in HPC. 2024.\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Import Necessary Packages\n",
    "\n",
    "The Thicket NCU reader requires an existing install of Nsight Compute, and the `extras/python` directory in the Nsight Compute installation directory must be added to the `PYTHONPATH`. We use `sys.path.append` to add the path to the `PYTHONPATH` in this notebook. If you are not on a Livermore Computing system, you must change this path to match your install of Nsight Compute.\n",
    "\n",
    "**VERSION NOTICE: This functionality is tested with nsight-compute version 2023.2.2. Your mileage may vary if using a different version.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d66ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T22:19:26.898836Z",
     "iopub.status.busy": "2024-03-26T22:19:26.898682Z",
     "iopub.status.idle": "2024-03-26T22:19:27.445595Z",
     "shell.execute_reply": "2024-03-26T22:19:27.445228Z"
    },
    "papermill": {
     "duration": 0.556743,
     "end_time": "2024-03-26T22:19:27.446317",
     "exception": false,
     "start_time": "2024-03-26T22:19:26.889574",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/usr/tce/packages/nsight-compute/nsight-compute-2023.2.2/extras/python\")\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import thicket as tt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47163338",
   "metadata": {},
   "source": [
    "## 2. The Dataset\n",
    "\n",
    "The dataset we are using comes from a profile of the RAJA Performance Suite on Lassen. We profile the `block_128` tuning of the `Base_CUDA`, `Lambda_CUDA`, and `RAJA_CUDA` variants, while varying the problem size for 1 million and 2 million. The calltree profiles come from the CUDA Activity Profile Caliper configuration. By changing the `variant` argument in the following cell, we can look at NCU data for different variants.\n",
    "\n",
    "The following are reproducible steps to generate this dataset:\n",
    "\n",
    "```\n",
    "# Example of building\n",
    "$ . RAJAPerf/scripts/lc-builds/blueos_nvhpc_nvcc_clang_caliper.sh \n",
    "$ make -j\n",
    "\n",
    "# Load CUDA version equal to the CUDA version used to build RAJAPerf\n",
    "$ module load nvhpc/24.1-cuda-11.2.0\n",
    "\n",
    "# Turn off NVIDIA Data Center GPU Manager (DCGM) on Lassen so we can run NCU (get an error if it's on)\n",
    "$ dcgmi profile --pause\n",
    "```\n",
    "\n",
    "```\n",
    "# Example run to Generate the CUDA Activity Profile\n",
    "$ CALI_CONFIG=cuda-activity-profile,output.format=cali lrun -n 1 --smpiargs=\"-disable_gpu_hooks\" bin/raja-perf.exe --variants [Base_CUDA OR Lambda_CUDA OR RAJA_CUDA] --tunings block_128 --size [1048576 OR 2097152] --repfact 0.01\n",
    "\n",
    "# Example run to Generate the NCU Report\n",
    "$ CALI_SERVICES_ENABLE=nvtx lrun -n 1 --smpiargs=\"-disable_gpu_hooks\" ncu \\\n",
    "--nvtx --set default \\\n",
    "--export report \\\n",
    "--metrics sm__throughput.avg.pct_of_peak_sustained_elapsed \\\n",
    "--replay-mode application \\\n",
    "bin/raja-perf.exe --variants [Base_CUDA OR Lambda_CUDA OR RAJA_CUDA] --tunings block_128 --size [1048576 OR 2097152] --repfact 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed93c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all files\n",
    "ncu_dir = \"../data/ncu/\"\n",
    "ncu_report_mapping = {}\n",
    "variant = \"base_cuda\" # OR \"lambda_cuda\" OR \"raja_cuda\"\n",
    "problem_sizes = [\"1M\", \"2M\"]\n",
    "for problem_size in problem_sizes:\n",
    "    full_path = f\"{ncu_dir}{variant}/{problem_size}/\"\n",
    "    ncu_report_mapping[full_path + \"report.ncu-rep\"] = full_path + \"cuda_profile.cali\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c694b",
   "metadata": {},
   "source": [
    "## 3. Read Calltree Profiles into Thicket\n",
    "\n",
    "The only performance metrics contained in the CUDA Activity Profile will be the CPU time `time` and the GPU time `time (gpu)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989da4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_cap = tt.Thicket.from_caliperreader(list(ncu_report_mapping.values()))\n",
    "tk_cap.dataframe.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9eff4",
   "metadata": {},
   "source": [
    "## 4. Add NCU Data\n",
    "\n",
    "The Thicket `add_ncu` function takes one required argument and one optional arguement. The required argument `ncu_report_mapping` is the mapping from the NCU report file to the corresponding calltree profile run. The optional argument `chosen_metrics` allows for a subselection of the NCU performance metrics to add, since there can be hundreds of NCU performance metrics. By default we add all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add NCU to thicket\n",
    "ncu_metrics = [\n",
    "    \"gpu__time_duration.sum\",\n",
    "    \"sm__throughput.avg.pct_of_peak_sustained_elapsed\",\n",
    "    \"smsp__maximum_warps_avg_per_active_cycle\",\n",
    "]\n",
    "# Add in metrics\n",
    "tk_cap.add_ncu(\n",
    "    ncu_report_mapping=ncu_report_mapping, \n",
    "    chosen_metrics=ncu_metrics,\n",
    ")\n",
    "tk_cap.dataframe.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ba22d",
   "metadata": {},
   "source": [
    "## 5. Visualize the NCU Performance Data on the Calltree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tk_cap.tree(\n",
    "    metric_column=\"sm__throughput.avg.pct_of_peak_sustained_elapsed\",\n",
    "    expand_name=True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2560242",
   "metadata": {},
   "source": [
    "## 6. Create Instruction Roofline Plots\n",
    "\n",
    "We can make roofline plots using the metrics we have collected using Nsight Compute. The Roofline sets an upper bound on performance of a kernel depending on its operational intensity. We will use roofline plots to understand the performance of RAJAPerf kernels.\n",
    "\n",
    "In this section, we reproduce some of the analysis and visualizations from the paper:\n",
    "\n",
    "Olga Pearce, Jason Burmark, Rich Hornung, Befikir Bogale, Ian Lumsden, Michael McKinsey, Dewi Yokelson, David Boehme, Stephanie Brink, Michela Taufer, and Tom Scogland. “RAJA Performance Suite: Performance Portability Analysis with Caliper and Thicket”. SC-W 2024: Workshops of ACM/IEEE International Conference for High Performance Computing, Networking, Storage, and Analysis. Performance, Portability & Productivity in HPC. 2024.\n",
    "\n",
    "Instruction Roofline Models were introduced by Ding et. al to better characterize GPU workloads by looking at instruction intensity. We walk through the creation of instruction roofline models for the Appications group of the RAJAPerf kernels below. \n",
    "\n",
    "More references on methodology for roofline models:\n",
    "\n",
    "* Samuel Williams, Andrew Waterman, and David Patterson. 2009. Roofline: an insightful visual performance model for multicore architectures. Commun. ACM 52, 4 (April 2009), 65–76. https://doi.org/10.1145/1498765.1498785\n",
    "\n",
    "* Nan Ding, Muaaz Awan, Samuel Williams. 2022. Instruction Roofline: An insightful visual performance model for GPUs. Concurrency and Computation: Practice and Experience\n",
    "https://doi.org/10.1002/cpe.6591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5073924",
   "metadata": {},
   "source": [
    "Step 1 is to create a Thicket using a CUDA Activity Profile, and add the NCU data. We use `RAJA_CUDA` variant data of the `block_256` tuning.\n",
    "\n",
    "Command to generate the Caliper CUDA Activity Profile:\n",
    "```\n",
    "CALI_CONFIG=cuda-activity-profile,output.format=cali lrun -n 1 --smpiargs=\"-disable_gpu_hooks\" bin/raja-perf.exe --variants RAJA_CUDA --tunings block_256 --size 8388608\n",
    "```\n",
    "\n",
    "Command to generate the NCU report with Roofline metrics:\n",
    "```\n",
    "CALI_SERVICES_ENABLE=nvtx lrun -n 1 --smpiargs=\"-disable_gpu_hooks\" ncu \\\n",
    "--nvtx --set default \\\n",
    "--export report \\\n",
    "--metrics sm__sass_thread_inst_executed.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum,l1tex__t_sectors_pipe_lsu_mem_local_op_ld.sum,l1tex__t_sectors_pipe_lsu_mem_local_op_st.sum,lts__t_sectors_op_read.sum,lts__t_sectors_op_write.sum,lts__t_sectors_op_atom.sum,lts__t_sectors_op_red.sum,dram__sectors_read.sum,dram__sectors_write.sum,l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum,l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum \\\n",
    "--replay-mode application \\\n",
    "bin/raja-perf.exe --variants RAJA_CUDA --tunings block_256 --size 8388608\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline_cali = ncu_dir + \"roofline/block_256_profile.cali\"\n",
    "roofline_ncu = ncu_dir + \"roofline/block_256_profile.ncu-rep\"\n",
    "\n",
    "# Unzip files, unless they have already been unzipped\n",
    "if not (os.path.isfile(roofline_cali) and os.path.isfile(roofline_ncu)):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(ncu_dir + \"roofline/block_256_profile.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(ncu_dir + \"roofline/\")\n",
    "\n",
    "# Create Thicket and add NCU data\n",
    "tk_roofline = tt.Thicket.from_caliperreader(roofline_cali)\n",
    "tk_roofline.add_ncu({roofline_ncu:roofline_cali})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58256cde",
   "metadata": {},
   "source": [
    "Select a subset of kernels to plot on the roofline. Here we are just selecting `Apps` kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54edcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options (can be more than one): [\"Algorithm\", \"Apps\", \"Basic\", \"Comm\", \"Lcals\", \"Polybench\", \"Stream\"]\n",
    "kernel_types = [\"Apps\"]\n",
    "\n",
    "raja_kernel_query = (\n",
    "    tt.query.Query()\n",
    "    .match (\n",
    "        \".\",\n",
    "        lambda row: row[\"name\"].apply(\n",
    "            lambda x: any([x.startswith(c + \"_\") for c in kernel_types])\n",
    "        ).all()\n",
    "    )\n",
    "    .rel(\"*\")\n",
    ")\n",
    "\n",
    "pruned_th = tk_roofline.query(raja_kernel_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab563417",
   "metadata": {},
   "source": [
    "Aggregate metrics for kernels with multiple instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match parent kernel name, e.g. \"Apps_VOL3D\"\n",
    "kernel_query = \"\"\"\n",
    "MATCH (\".\",p)->(\"*\")\n",
    "WHERE p.\"name\" = \"{ker}\"\n",
    "\"\"\"\n",
    "\n",
    "# Match demangled kernel that contains NCU measurement.\n",
    "child_kernel_query = \"\"\"\n",
    "MATCH (\".\", p)\n",
    "WHERE p.\"depth\" = 2\n",
    "\"\"\"\n",
    "\n",
    "# List of columns to exclude from aggregation\n",
    "cols = [col for col in pruned_th.dataframe.columns.tolist() if col not in [\"nid\", \"time\", \"name\", \"time (inc)\", \"time (gpu) (inc)\"]]\n",
    "leaves = []\n",
    "\n",
    "for n in pruned_th.graph.roots:\n",
    "    kernels = {}\n",
    "    \n",
    "    kernels[\"name\"] = n.frame.get(\"name\")\n",
    "\n",
    "    tmp = kernel_query.format(ker=n.frame.get(\"name\"))\n",
    "    ker_th = pruned_th.query(tmp, multi_index_mode=\"all\")\n",
    "    leaf = ker_th.query(child_kernel_query, multi_index_mode=\"all\")\n",
    "    for col in cols:\n",
    "        kernels[col] = leaf.dataframe[col].sum()\n",
    "    \n",
    "    leaves.append(kernels)\n",
    "\n",
    "agg_df = pd.DataFrame(data=leaves)\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09a71b",
   "metadata": {},
   "source": [
    "Calculate instruciton intensities from existing NCU metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "513e02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp Instructions\n",
    "agg_df[\"Warp Instructions\"] = agg_df[\"sm__sass_thread_inst_executed.sum\"] / 32\n",
    "# L1 Global Count Memory Transactions\n",
    "agg_df[\"L1 (GLOBAL)\"] = agg_df[\"l1tex__t_sectors_pipe_lsu_mem_global_op_ld.sum\"] + agg_df[\"l1tex__t_sectors_pipe_lsu_mem_global_op_st.sum\"]\n",
    "agg_df[\"L1 (SHARED)\"] = agg_df[\"l1tex__data_pipe_lsu_wavefronts_mem_shared_op_ld.sum\"] + agg_df[\"l1tex__data_pipe_lsu_wavefronts_mem_shared_op_st.sum\"]\n",
    "agg_df[\"Total L1 Transactions\"] = agg_df[\"L1 (GLOBAL)\"] + (4 * agg_df[\"L1 (SHARED)\"])\n",
    "# Shared Count Memory Transactions\n",
    "agg_df[\"L2 Write Transactions\"] =  agg_df[\"lts__t_sectors_op_write.sum\"] + agg_df[\"lts__t_sectors_op_atom.sum\"] + agg_df[\"lts__t_sectors_op_red.sum\"]\n",
    "agg_df[\"L2 Read Transactions\"] =  agg_df[\"lts__t_sectors_op_read.sum\"] + agg_df[\"lts__t_sectors_op_atom.sum\"] + agg_df[\"lts__t_sectors_op_red.sum\"]\n",
    "agg_df[\"Total L2 Transactions\"] = agg_df[\"L2 Read Transactions\"] + agg_df[\"L2 Write Transactions\"]\n",
    "# HBM Count Memory Transactions\n",
    "agg_df[\"HBM Transactions\"] = agg_df[\"dram__sectors_read.sum\"] +  agg_df[\"dram__sectors_write.sum\"]\n",
    "# L1, L2, HBM Intensities\n",
    "agg_df[\"L1 Instruction Intensity\"] = agg_df[\"Warp Instructions\"] / agg_df[\"Total L1 Transactions\"]\n",
    "agg_df[\"L2 Instruction Intensity\"] = agg_df[\"Warp Instructions\"] / agg_df[\"Total L2 Transactions\"]\n",
    "agg_df[\"HBM Instruction Intensity\"] = agg_df[\"Warp Instructions\"] / agg_df[\"HBM Transactions\"]\n",
    "# Performance in GIPS\n",
    "agg_df[\"Performance GIPS\"] = agg_df[\"Warp Instructions\"] / (agg_df[\"time (gpu)\"] * (10 ** 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db197b",
   "metadata": {},
   "source": [
    "### Plotting Roofline with Matplotlib\n",
    "\n",
    "The plotting code below was adapted from the following resource: https://gitlab.com/NERSC/roofline-on-nvidia-gpus/-/blob/master/custom-scripts/roofline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "909bbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_th_kers = tk_roofline.query(child_kernel_query, multi_index_mode=\"all\")\n",
    "metrics = [\"L1 Instruction Intensity\", \"L2 Instruction Intensity\", \"HBM Instruction Intensity\"]\n",
    "\n",
    "c_s = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"cyan\", \"magenta\"]\n",
    "final_colors = []\n",
    "for i in agg_df[\"name\"].tolist():\n",
    "    for j in range(0, len(kernel_types)):\n",
    "        if i.startswith(kernel_types[j]):\n",
    "            final_colors.append(c_s[j])\n",
    "            continue\n",
    "\n",
    "font = {\"size\": 15}\n",
    "plt.rc(\"font\", **font)\n",
    "\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
    "styles = [\"o\", \"s\", \"v\", \"^\", \"D\", \">\", \"<\", \"*\", \"h\", \"H\", \"+\", \"1\", \"2\", \"3\", \"4\", \"8\", \"p\", \"d\", \"|\", \"_\", \".\", \",\"]\n",
    "\n",
    "markersize = 10\n",
    "markerwidth = 2\n",
    "maxchar = 25\n",
    "\n",
    "def roofline(LABELS, flag=\"HBM\", data_df=None):\n",
    "    LABELS = [x[:maxchar] for x in LABELS]\n",
    "    \n",
    "    bandiwdth_hbm = 25.9 # in GTXN/s\n",
    "    bandwidth_l2 = 93.6 # in GTXN/s\n",
    "    bandwidth_l1 = 437.5 # in GTXN/s\n",
    "    \n",
    "    if flag == \"L1\":\n",
    "        memRoofs = [(\"L1\", bandwidth_l1)]\n",
    "    elif flag == \"L2\":\n",
    "        memRoofs = [(\"L2\", bandwidth_l2)]\n",
    "    elif flag == \"HBM\":\n",
    "        memRoofs = [(\"HBM\", bandiwdth_hbm)]\n",
    "    elif flag == \"all\":\n",
    "        memRoofs = [(\"L1\", bandwidth_l1), (\"L2\", bandwidth_l2),  (\"HBM\", bandiwdth_hbm)]\n",
    "\n",
    "    cmpRoofs = [(\"GIPS\", 489.6)]\n",
    "\n",
    "    fig = plt.figure(1, figsize=(10,6))\n",
    "    plt.clf()\n",
    "    ax = fig.gca()\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Instruction Intensity [Warp Instructions/transaction]\")\n",
    "    ax.set_ylabel(\"Performance [Warp GIPS]\")\n",
    "\n",
    "    nx   = 10000\n",
    "    xmin = -3 \n",
    "    xmax = 3\n",
    "    ymin = 1\n",
    "    ymax = 1000\n",
    "\n",
    "    ax.set_xlim(10 ** xmin, 10 ** xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    ixx = int(nx * 0.02)\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    scomp_x_elbow  = []\n",
    "    scomp_ix_elbow = []\n",
    "    smem_x_elbow   = []\n",
    "    smem_ix_elbow  = []\n",
    "\n",
    "    x = np.logspace(xmin, xmax, nx)\n",
    "    for roof in cmpRoofs:\n",
    "        for ix in range(1, nx):\n",
    "            if float(memRoofs[0][1] * x[ix]) >= roof[1] and (memRoofs[0][1] * x[ix - 1]) < roof[1]:\n",
    "                scomp_x_elbow.append(x[ix - 1])\n",
    "                scomp_ix_elbow.append(ix - 1)\n",
    "                break\n",
    "\n",
    "    for roof in memRoofs:\n",
    "        for ix in range(1, nx):\n",
    "            if (cmpRoofs[0][1] <= roof[1] * x[ix] and cmpRoofs[0][1] > roof[1] * x[ix - 1]):\n",
    "                smem_x_elbow.append(x[ix - 1])\n",
    "                smem_ix_elbow.append(ix - 1)\n",
    "                break\n",
    "\n",
    "    for i in range(len(cmpRoofs)):\n",
    "        roof = cmpRoofs[i][1]\n",
    "        y = np.ones(len(x)) * roof\n",
    "        ax.plot(x[scomp_ix_elbow[i]:], y[scomp_ix_elbow[i]:], c=\"k\", ls=\"-\", lw=\"2\")\n",
    "\n",
    "    for i in range(len(memRoofs)):\n",
    "        roof = memRoofs[i][1]\n",
    "        y = x * roof\n",
    "        ax.plot(x[:smem_ix_elbow[i] + 1], y[:smem_ix_elbow[i] + 1], c=\"k\", ls=\"-\", lw=\"2\")\n",
    "\n",
    "    for roof in cmpRoofs:\n",
    "        ax.text(\n",
    "            x[-ixx],\n",
    "            roof[1],\n",
    "            roof[0] + \": \" + \"{0:.1f}\".format(roof[1]) + \" Warp GIPS\",\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"bottom\"\n",
    "        )\n",
    "\n",
    "    for roof in memRoofs:\n",
    "        ang = np.arctan(np.log10(xlim[1] / xlim[0]) / np.log10(ylim[1] / ylim[0])\n",
    "                                   * fig.get_size_inches()[1] / fig.get_size_inches()[0] )\n",
    "        if x[ixx]*roof[1] > ymin:\n",
    "            ax.text(\n",
    "                x[ixx],\n",
    "                x[ixx] * roof[1] * (1 + 0.25 * np.sin(ang) ** 2),\n",
    "                roof[0] + \": \" + \"{0:.1f}\".format(float(roof[1])) + \" GTXN/s\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"bottom\",\n",
    "                rotation=180 / np.pi * ang\n",
    "            )\n",
    "        else:\n",
    "            ymin_ix_elbow=list()\n",
    "            ymin_x_elbow=list()\n",
    "            for ix in range(1, nx):\n",
    "                if (ymin <= roof[1] * x[ix] and ymin > roof[1] * x[ix - 1]):\n",
    "                    ymin_x_elbow.append(x[ix - 1])\n",
    "                    ymin_ix_elbow.append(ix - 1)\n",
    "                    break\n",
    "            ax.text(\n",
    "                x[ixx+ymin_ix_elbow[0]],\n",
    "                x[ixx+ymin_ix_elbow[0]] * roof[1] * (1 + 0.25 * np.sin(ang) ** 2) * 1.15,\n",
    "                roof[0] + \": \" + \"{0:.1f}\".format(float(roof[1])) + \" GTXN/s\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"bottom\",\n",
    "                rotation=180 / np.pi * ang\n",
    "            )\n",
    "\n",
    "    if flag == \"L1\":\n",
    "        ax.scatter(data_df[metrics[0]], data_df[\"Performance GIPS\"], c=final_colors, label=\"L1\", marker=styles[0])\n",
    "    elif flag == \"L2\":\n",
    "        ax.scatter(data_df[metrics[1]], data_df[\"Performance GIPS\"], c=final_colors, label=\"L2\", marker=styles[1])\n",
    "    elif flag == \"HBM\":\n",
    "        ax.scatter(data_df[metrics[2]], data_df[\"Performance GIPS\"], c=final_colors, label=\"HBM\", marker=\"*\")\n",
    "\n",
    "    elif flag == \"all\":\n",
    "        ax.scatter(data_df[metrics[0]], data_df[\"Performance GIPS\"], c=final_colors, label=\"L1\", marker=styles[0])\n",
    "        ax.scatter(data_df[metrics[1]], data_df[\"Performance GIPS\"], c=final_colors, label=\"L2\", marker=styles[1])\n",
    "        ax.scatter(data_df[metrics[2]], data_df[\"Performance GIPS\"], c=final_colors, label=\"HBM\", marker=\"*\")\n",
    "\n",
    "    custom_labels = [k.split(\"_\")[0] for k in kernel_types]\n",
    "    custom_handles = [plt.Line2D([0], [0], color=i, lw=2) for i in c_s]\n",
    "    \n",
    "    if flag == \"HBM\":\n",
    "        leg2 = ax.legend(\n",
    "            custom_handles,\n",
    "            custom_labels,\n",
    "            bbox_to_anchor=(0.36, 1),\n",
    "            title=\"Kernel Types\",\n",
    "            fontsize=\"12\",          # Adjust label font size (e.g., \"small\", \"medium\", \"large\", or specific size)\n",
    "            title_fontsize=\"small\"\n",
    "        )\n",
    "    else:\n",
    "        leg2 = ax.legend(\n",
    "            custom_handles,\n",
    "            custom_labels,\n",
    "            bbox_to_anchor=(0.36, 1),\n",
    "            title=\"Kernel Types\",\n",
    "            fontsize=\"12\",          # Adjust label font size (e.g., \"small\", \"medium\", \"large\", or specific size)\n",
    "            title_fontsize=\"small\"\n",
    "        )\n",
    "        \n",
    "    ax.add_artist(leg2)\n",
    "    \n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline(LABELS=pruned_th.dataframe[\"name\"].tolist(), flag=\"all\", data_df=agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline(LABELS=pruned_th.dataframe[\"name\"].tolist(), flag=\"L1\", data_df=agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline(LABELS=pruned_th.dataframe[\"name\"].tolist(), flag=\"L2\", data_df=agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline(LABELS=pruned_th.dataframe[\"name\"].tolist(), flag=\"HBM\", data_df=agg_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.570405,
   "end_time": "2024-03-26T22:19:29.810540",
   "environment_variables": {},
   "exception": null,
   "input_path": "01_thicket_tutorial.ipynb",
   "output_path": "01_thicket_tutorial.ipynb",
   "parameters": {},
   "start_time": "2024-03-26T22:19:26.240135",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
