{
  "openai" : { "exec"            :"${LLMTOOLS:HOME}/etc/llmtools/gpt4/exec-openai.sh",
               "execFlags"       :"${LLMTOOLS:MODEL}",
               "defaultModel"    :"gpt-4o",
               "responseFile"    :"response.json",
               "responseField"   :"choices[0].message.content",
               "systemTextFile"  :"",
               "roleOfAI"        :"assistant",
               "queryFile"       :"query.json",
               "apiKeyName"      :"OPENAI_API_KEY",
               "alternativeNames":["openai","gpt4o"]
             },
  "claude" : { "exec"          :"${LLMTOOLS:HOME}/etc/llmtools/claude/exec-claude.sh",
               "execFlags"       :"${LLMTOOLS:MODEL}",
               "defaultModel"    :"claude-sonnet-4-5",
               "responseFile"    :"response.json",
               "responseField"   :"content[0].text",
               "systemTextFile"  :"system.txt",
               "roleOfAI"        :"assistant",
               "queryFile"       :"query.json",
               "apiKeyName"      :"ANTHROPIC_API_KEY",
               "alternativeNames":["claude", "anthropic"]
             },
  "ollama" : { "exec"            :"${LLMTOOLS:HOME}/etc/llmtools/ollama/exec-ollama.sh",
               "execFlags"       :"${LLMTOOLS:MODEL}",
               "defaultModel"    :"llama3.3",
               "responseFile"    :"response.json",
               "responseField"   :"message.content",
               "systemTextFile"  :"",
               "roleOfAI"        :"assistant",
               "queryFile"       :"query.json",
               "alternativeNames":["ollama"]
             },
  "openrouter" : { "exec"        :"${LLMTOOLS:HOME}/etc/llmtools/openrouter/exec-openrouter.sh",
               "execFlags"       :"${LLMTOOLS:MODEL}",
               "defaultModel"    :"google/gemini-2.0-flash-exp:free",
               "responseFile"    :"response.json",
               "responseField"   :"message.content",
               "systemTextFile"  :"",
               "roleOfAI"        :"assistant",
               "queryFile"       :"query.json",
               "apiKeyName"      :"OPENROUTER_API_KEY",
               "alternativeNames":["openrouter"]
             },
  "llamacli" : { "exec"          :"${LLMTOOLS:HOME}/etc/llmtools/llama-cli/exec-llama.sh",
               "execFlags"       :"${LLMTOOLS:MODEL}",
               "defaultModel"    :"-hf ggml-org/gemma-3-1b-it-GGUF",
               "responseFile"    :"response.log",
               "responseField"   :"",
               "systemTextFile"  :"system.txt",
               "roleOfAI"        :"model",
               "queryFile"       :"query.txt",
              },
               "alternativeNames":["llamacli","llama-cli"]
             },
  "none"   : { "exec"            :"",
               "defaultModel"    :"",
               "responseFile"    :"",
               "responseField"   :"",
               "systemTextFile"  :"",
               "roleOfAI"        :"",
               "queryFile"       :"",
               "alternativeNames":["none", "custom","user-defined","userdefined"]
             },
  "help"   : { "exec"            :"script handling model invocation",
               "execFlags"       :"arguments for exec invocation",
               "defaultModel"    :"the default model",
               "responseFile"    :"file where the model stores the response",
               "responseField"   :"if JSON, the field stores the access path to the response",
               "systemTextFile"  :"file to store the system text, if it is not part of a JSON input",
               "roleOfAI"        :"role of AI",
               "queryFile"       :"history file",
               "promptFile"      :"structure description of query as uploaded to server (may not be used)",
               "apiKeyName"      :"Name of key that is read from the environment",
               "alternativeNames":["help", "set of alternative model names"]
             }
}
