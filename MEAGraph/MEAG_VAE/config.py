import logging
from yacs.config import CfgNode as CN
import torch
import os

# Create a ConfigNode object
cfg = CN()

def set_cfg(cfg):
    """
    Set the default configuration values.
    
    Args:
        cfg (CfgNode): Configuration node.
    """
    # Device settings
    cfg.device = 'cuda:1'  # Device to use for training and inference ('cuda:1' or 'cpu')
    cfg.torch_real = 'torch.float32'  # Torch data type for real numbers

    # Output directory
    cfg.out_dir = 'results'  # Directory to save the results
    cfg.cfg_dest = 'config.yaml'  # Destination file name for the configuration

    # Data loading settings
    cfg.num_workers = 0  # Number of workers for data loading
    cfg.num_threads = 4  # Maximum number of threads used by PyTorch

    # Dataset settings
    cfg.dataset = CN()
    cfg.dataset.elem = 'Nb'  # Element name
    cfg.dataset.dir_name = 'datasets'  # Directory name for the dataset
    cfg.dataset.feature_type = 'soap'  # Feature type for the dataset

    # Training settings
    cfg.train = CN()
    cfg.train.batch_size = 8  # Batch size for training
    cfg.train.train_val_ratio = 0.9  # Ratio of training data to validation data
    cfg.train.epochs = 20  # Number of training epochs

    # Optimization settings
    cfg.optim = CN()
    cfg.optim.opt = 'adam'  # Optimizer ('adam' or 'sgd')
    cfg.optim.scheduler = 'step'  # Learning rate scheduler ('step' or 'cosine')
    cfg.optim.lr = 1e-3  # Learning rate
    cfg.optim.weight_decay = 5e-4  # L2 regularization weight decay
    cfg.optim.opt_decay_step = 15  # Step size for learning rate decay
    cfg.optim.opt_decay_rate = 0.65  # Decay rate for learning rate
    cfg.optim.opt_restart = 0  # Number of restarts for the optimizer

    # Model settings
    cfg.model = CN()
    cfg.model.channels = "32,16,8"  # Number of channels in each layer
    cfg.model.num_kernels = 3  # Number of kernels in the model
    cfg.model.num_depth = 2  # Number of depth levels in the model
    cfg.model.pooling_rate = -1.0  # Pooling rate for edge_reduction in encoder layers (-1 for adaptive pooling, i.e. random sampling of pooling rate while training)
    cfg.model.fixed_rate_l = 0.9 - 1e-5  # Lower rate for edge selection of build_graph function in utils.py
    cfg.model.fixed_rate_r = 1 + 1e-5  # Upper rate for edge selection of build_graph function in utils.py
    cfg.model.save_dir = 'model_saved'  # Directory to save the trained model
    cfg.model.file_name = 'Nb'  # File name for the saved model
    cfg.model.edge_reduction = 'score_adaptive'  # Edge reduction method

    # Test settings
    cfg.test = CN()
    cfg.test.xyz_dir = 'test'  # Directory for the test files generated by inferecen.py

def load_cfg(cfg, args):
    """
    Load configurations from file system and command line.
    
    Args:
        cfg (CfgNode): Configuration node.
        args (ArgumentParser): Command argument parser.
    """
    cfg.merge_from_file(args.cfg_file)
    cfg.merge_from_list(args.opts)
    if args.device is not None:
        cfg.device = args.device

def dump_cfg(cfg):
    """
    Dump the configuration to the output directory.
    
    Args:
        cfg (CfgNode): Configuration node.
    """
    cfg_file = os.path.join(cfg.out_dir, cfg.cfg_dest)
    with open(cfg_file, 'w') as f:
        cfg.dump(stream=f)

def update_out_dir(out_dir, fname):
    """
    Update the output directory based on the given directory and file name.
    
    Args:
        out_dir (str): Output directory.
        fname (str): File name.
    """
    fname = fname.split('/')[-1][:-5]
    cfg.out_dir = os.path.join(out_dir, fname)
    os.makedirs(cfg.out_dir, exist_ok=True)

# Set the default configuration values
set_cfg(cfg)