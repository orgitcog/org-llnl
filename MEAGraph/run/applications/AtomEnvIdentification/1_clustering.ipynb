{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on the SOAP Descriptors for Atom Environment Identification\n",
    "\n",
    "In this section, we perform clustering on the SOAP descriptors to identify atomic environments for a given Nb structure. The clustering process involves training the MEAGraph autoencoder, inference on specific structures, saving cluster labels for visualization, and comparing the results with other clustering methods.The Nb datasets are obtained from Sun, H. et al, Computational Materials Science, 230, p. 112497, 2023.\n",
    "1. **MEAGraph Autoencoder Training:**\n",
    "- Train the MEAGraph autoencoder on the Nb dataset.\n",
    "- The trained model will be used for clustering the SOAP feature matrix.\n",
    "\n",
    "2. **Inference:**\n",
    "- Specify the structure ID for investigation (check available structures in `Nb_CONTCARs`).\n",
    "- Cluster the SOAP feature matrix using the loaded MEAGraph model (`results` folder) to identify atomic environments.\n",
    "\n",
    "3. **Save Cluster Labels for Visualization:**\n",
    "- Save the cluster labels obtained from MEAGraph as the artificial `charges` in the atoms object.\n",
    "- Visualize the xyz file using OVITO and check the clusters by color coding.\n",
    "4. **Compare with Other Clustering Methods**\n",
    "- Apply other clustering methods to the SOAP feature matrix for comparison: e.g., Affinity Propagation, K-means\n",
    "- Compare the clustering results obtained from MEAGraph with these alternative methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GAE Training\n",
    "\n",
    "- Specify the configuration settings in the `YAML` file located in the `configs` folder. For example, set device to either cuda or cpu depending on your system.\n",
    "- Convert the structures in the Nb_CONCTARs dataset to ASE atoms XYZ format and save the file as train.xyz in the `raw/raw_Nb_soap` folder.\n",
    "- Run `python main.py --cfg configs/user-defined-config.yaml` in the notebook or on the terminal or submit the job to the cluster if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "# Get the current working directory\n",
    "#current_dir=os.getcwd()\n",
    "#Uncomment to specify the absolute path if `os.getcwd` not working\n",
    "current_dir = f\"/usr/workspace/sun36/MEAGraph/run/applications/AtomEnvIdentification\"  # change it to your working directory\n",
    "\n",
    "# Change the working directory to \"run_dir\"\n",
    "main_dir = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "yaml_file='Nb_soap'\n",
    "os.chdir(main_dir)\n",
    "\n",
    "# Run GAE training (if not working try to run it in the terminal or submit the job to the cluster )\n",
    "command=f'python main.py --cfg configs/{yaml_file}.yaml'\n",
    "#Uncomment to run the main.py on this notebook\n",
    "#subprocess.run(command,shell=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Inference \n",
    "\n",
    "  - Specify the structure ID  for clustering (check available structures in `Nb_CONTCARs` folder)\n",
    "  - run `python inference.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.chdir(main_dir)\n",
    "\n",
    "#define the parameters\n",
    "\n",
    "group_name_strs='84' # structure ID is 84\n",
    "group_name_list=[group_name_strs]\n",
    "fixed_rate_l=0.8  #'Lower rate for edge selection of build_graph function'\n",
    "rate=0.3     #'self-defined pooling rate for edge_reduction in Encoder layers'\n",
    "train_val_ratio=1.0 #'ratio of training data to test data for the force field fitting using inference.py'\n",
    "yaml_file='Nb_soap'\n",
    "# Load the YAML file\n",
    "with open(f'{main_dir}/configs/{yaml_file}.yaml', \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "# Get the name of result dir\n",
    "test_dir = config['test']['xyz_dir']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `inference.py` to obtain the clustering results for the selected structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss is: 0.0013985219411551952\n",
      "total number of atoms: 1280, number of isolated atoms: 0\n"
     ]
    }
   ],
   "source": [
    "result_dir=f\"{main_dir}/results/{yaml_file}/{test_dir}\"\n",
    "jsonfile_path=f\"{result_dir}/clusters_{group_name_strs}_r{rate}_train{train_val_ratio}.json\"\n",
    "\n",
    "if not os.path.exists(jsonfile_path):\n",
    "    command = f'python inference.py --cfg configs/{yaml_file}.yaml --group_name {group_name_strs}  --rate {rate}  --train_val_ratio {train_val_ratio}  --device cpu'\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "# Change the working directory back to the original directory\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved clustering results, merge the feature matrix and save them to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "\n",
    "with open(jsonfile_path,'r') as json_file:\n",
    "    node_info=json.load(json_file)\n",
    "new_columns = {0: 'cluster_idx', 1: 'cluster_size'}\n",
    "df_info = pd.DataFrame.from_dict(node_info,orient='index')\n",
    "df_info.rename(columns=new_columns,inplace=True)\n",
    "df_info.reset_index(inplace=True)\n",
    "df_info.rename(columns={'index':'Atom_ID'},inplace=True)\n",
    "df_info['Atom_ID'] = df_info['Atom_ID'].astype(int)  \n",
    "\n",
    "data=torch.load(f\"{result_dir}/graph_{group_name_strs}_train{train_val_ratio}_data.pt\")\n",
    "df_feats=pd.DataFrame(data.x)\n",
    "df_feats.reset_index(inplace=True)\n",
    "df_feats.rename(columns={'index':'Atom_ID'},inplace=True)\n",
    "\n",
    "df=pd.merge(df_feats,df_info,on='Atom_ID')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Save Cluster Labels for Visualization\n",
    "- Save the cluster labels obtained from MEAGraph as the artificial `charges` in the atoms object.\n",
    "- Visualize the xyz file using OVITO and check the clusters by color coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ase.io\n",
    "\n",
    "charges=df['cluster_idx']\n",
    "charges=np.array(charges)\n",
    "config_id=int(group_name_strs)+1\n",
    "atom=ase.io.read('Nb_CONTCARs/CONTCAR'+str(config_id))\n",
    "\n",
    "atom.arrays['charge']=charges\n",
    "ase.io.write(f'{config_id}_{rate}.xyz',atom,format='extxyz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the DFT force magnitude values (in `Nb_forces` folder) as the `charges` label for the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forces=np.loadtxt(f'Nb_Forces/force_Cfg{config_id}')\n",
    "forces=np.linalg.norm(forces, axis=1)\n",
    "config_id=int(group_name_strs)+1\n",
    "atom=ase.io.read('Nb_CONTCARs/CONTCAR'+str(config_id))\n",
    "atom.arrays['charge']=forces\n",
    "ase.io.write(f'{config_id}_force.xyz',atom,format='extxyz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Compare with Other Clustering Methods\n",
    "Apply other clustering methods to the SOAP feature matrix for comparison:\n",
    " - Affinity Propagation\n",
    " - K-means\n",
    " - Spectral Clustering\n",
    " - DBSCAN\n",
    " - Mean Shift\n",
    " - Gaussian Mixture Models (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/sun36/fitSNAP/fitsnap/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import ase.io\n",
    "atom=ase.io.read('Nb_CONTCARs/CONTCAR'+str(config_id))\n",
    "\n",
    "# bandwidth=2\n",
    "# mean_shift = MeanShift(bandwidth=bandwidth)\n",
    "# labels = mean_shift.fit_predict(data.x)\n",
    "\n",
    "# n_clusters=6\n",
    "# # Apply spectral clustering\n",
    "# spectral_clustering = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', random_state=42)\n",
    "# labels = spectral_clustering.fit_predict(numeric_df)\n",
    "\n",
    "# damping=0.5\n",
    "# affinity_propagation = AffinityPropagation(damping=damping)\n",
    "clusters = AffinityPropagation().fit(data.x)\n",
    "# labels = affinity_propagation.fit_predict(X_embedded)\n",
    "#labels = mean_shift.fit_predict(X_embedded)\n",
    "\n",
    "# gmm = GaussianMixture(n_components=15, random_state=42)\n",
    "# labels = gmm.fit_predict(numeric_df)\n",
    "\n",
    "# n_clusters=6\n",
    "# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# labels = kmeans.fit_predict(numeric_df)\n",
    "# labels = kmeans.fit_predict(X_embedded)\n",
    "\n",
    "# clusters=DBSCAN().fit(data.x)\n",
    "#ase.io.write(f'{config_id}_affinity_{damping}.xyz',atom,format='extxyz')\n",
    "#ase.io.write(f'{config_id}_kmeans_{n_clusters}.xyz',atom,format='extxyz')\n",
    "\n",
    "# ase.io.write(f'{config_id}_spectral_{n_clusters}.xyz',atom,format='extxyz')\n",
    "\n",
    "charges=clusters.labels_\n",
    "charges=np.array(charges)\n",
    "atom.arrays['charge']=charges\n",
    "# ase.io.write(f'{config_id}_meanshift_b{bandwidth}.xyz',atom,format='extxyz')\n",
    "ase.io.write(f'{config_id}_affinity.xyz',atom,format='extxyz')\n",
    "#ase.io.write(f'{config_id}_DBSCAN.xyz',atom,format='extxyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
