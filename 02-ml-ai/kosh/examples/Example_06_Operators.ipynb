{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kosh Operators\n",
    "\n",
    "This notebook introduces Kosh's *operators*. Unlike *transformers*, which act on a feature itself, *operators* allow post-processing of data coming from different features, for example adding two features together. Either from the same source or not.\n",
    "\n",
    "Kosh operators will receive the input features as Python's `*args`.\n",
    "\n",
    "Operators inputs can be features coming straight from the loader, possibly processed by a(many) *transformer(s)* and/or coming from another *operator*.\n",
    "\n",
    "While one could be be getting each feature individually and then use a raw function on them, operators offer many advantages.\n",
    "\n",
    "* When mixing data from multiple sources, and possibly transformers, Kosh will automatically determine which loaders to use and which output format is required from each loader (and transformers) in order for all data to be compatible when passed to the operator.\n",
    "* Operators can be built (`__getitem__` function see [this notebook](Example_Advanced_Data_Slicing.ipynb) ) to read in only the amount of data needed.\n",
    "\n",
    "\n",
    "## Easiest way: Decorators\n",
    "\n",
    "As with `transformers` one can use Python `decorators` to quickly convert an existing function.\n",
    "\n",
    "Let's import some modules, create a store and a dataset to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/moreno45/Projects/ASCAML/kosh/kosh/utils.py:522: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "[[74.60042   22.704462  81.75976   43.019024  90.3619    27.78305\n",
      "  71.98507   38.78283   31.862976  12.7631855 94.52985   74.529434\n",
      "  18.101988  57.22014   50.838238  75.56943   21.334723  63.617054 ]\n",
      " [30.224789  70.80611   62.686962  19.330027  81.621056  93.60426\n",
      "  21.645191  63.31401   92.55467   90.84677   27.292467  14.005975\n",
      "  49.63301   85.57087    9.917352  58.027737  69.95087    5.07952  ]]\n",
      "extract numpy\n",
      "['numpy']\n",
      "[[24.176632  28.35887   57.926807  88.42995   43.800083  59.017242\n",
      "  22.848253   7.5056286  2.5399094  6.2492366 46.997864  60.64453\n",
      "  30.870817  66.92705   46.292072  27.467634  84.07651   68.11991  ]\n",
      " [73.90602   55.195995  84.13312   79.93733   13.419014  60.481445\n",
      "  64.483665   9.53269   56.463535  92.742775  88.28038   16.180855\n",
      "   4.254545   9.790927  67.85503    1.1167012 63.09269   49.717033 ]]\n"
     ]
    }
   ],
   "source": [
    "import kosh\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import sys, os\n",
    "store = kosh.connect(\"operators_demo.sql\", delete_all_contents=True)\n",
    "ds = store.create()\n",
    "ds.associate(\"../tests/baselines/node_extracts2/node_extracts2.hdf5\", mime_type=\"hdf5\")\n",
    "\n",
    "m1 = ds[\"node/metrics_0\"]\n",
    "print(m1[:][:])\n",
    "m2 = ds[\"node/metrics_2\"]\n",
    "print(m2[:][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assuming you have a function that adds up your features for numpy arrays. Let's make it a Kosh operator.\n",
    "\n",
    "*Note:* `numpy_operators` will declare the operator's `types` to be `{'numpy': [\"numpy\",]}`. See later for declaring your custom `types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]]\n"
     ]
    }
   ],
   "source": [
    "@kosh.numpy_operator\n",
    "def Add(*inputs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    return out\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to *loaders* and *transformers*, *operators* must declare the mime_types they can accept as inputs and the mime_types they export these inputs to. Where the *transformers* process the feature via their `transform` function, *operators* must define their `operate` function.\n",
    "\n",
    "At the moment it is expected that all inputs must be from the same mime_type.\n",
    "\n",
    "Let's create an operator while defninig these *mime_types*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]]\n"
     ]
    }
   ],
   "source": [
    "@kosh.typed_operator({\"numpy\":[\"numpy\",]})\n",
    "def Add(*inputs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    return out\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again just like loaders and transformers, operator can return the output in multiple format, in this case the decorated function must accept the \"format\" key argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]] <class 'numpy.ndarray'>\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]] <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "@kosh.typed_operator_with_kwargs({\"numpy\":[\"numpy\",\"str\"]})\n",
    "def Add(*inputs, **kwargs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    if kwargs[\"format\"] == \"numpy\":\n",
    "        return out\n",
    "    elif kwargs[\"format\"] == \"str\":\n",
    "        return str(out)\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add(format=\"numpy\"), type(add(format=\"numpy\")))\n",
    "print(add(format=\"str\"), type(add(format=\"str\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A warning about indices\n",
    "\n",
    "Kosh decorators will provide an operator that will pass through the indices a user asked for (for efficiency).\n",
    "See [this notebook](Example_Advanced_Data_Slicing.ipynb) for cases where this will return the wrong answer (e.g a operator that flips the order of the input).\n",
    "\n",
    "## Operator from scratch\n",
    "\n",
    "In this example we will define a simple **Add** operator that will add all the inputs it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(kosh.KoshOperator):\n",
    "    types = {\"numpy\" : [\"numpy\",]}  # Our operator accepts numpy arrays and outputs numpy arrays\n",
    "    \n",
    "    def operate(self, *inputs, ** kargs):\n",
    "        # *inputs are the input received from their predecessors in the execution graph\n",
    "        # It is important to define **kargs as the function will receive `format=some_format`\n",
    "        out = np.array(inputs[0])\n",
    "        for input_ in inputs[1:]:\n",
    "            out += np.array(input_)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important points**:\n",
    "\n",
    "  * The `operate` function will receive the desired output format via `format=output_format` so it *must* declare `**kargs`\n",
    "  * inputs are sent via `*inputs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[22 16]\n"
     ]
    }
   ],
   "source": [
    "f1 = ds[\"cycles\"]\n",
    "add = Add(f1, f1)\n",
    "\n",
    "print(add[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned we can also pass the feature through a transformer first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[33. 24.]\n"
     ]
    }
   ],
   "source": [
    "class Twice(kosh.transformers.KoshTransformer):\n",
    "    types = {\"numpy\":[\"numpy\",]}\n",
    "    def transform(self, input, format):\n",
    "        return np.array(input) * 2.\n",
    "    \n",
    "twice = Twice()\n",
    "\n",
    "f1 = ds.get_execution_graph(\"cycles\", transformers=[twice,])\n",
    "f2 = ds[\"cycles\"]\n",
    "\n",
    "add2 = Add(f1, f2)\n",
    "print(add2[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have an operator as an input to another, and mix and match this with regular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "[55. 40.]\n"
     ]
    }
   ],
   "source": [
    "add3 = Add(add2, add)\n",
    "print(add3[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes these can get complicated and hard to follow.\n",
    "You can draw the execution graph to see if everything is happening as you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kosh.utils.draw_execution_graph(add3.execution_graph(), png_name=\"exec_graph.png\", output_format=\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Execution Graph](exec_graph.png)\n",
    "\n",
    "Lastly it is worth noting that transformers and operators can implement their own `__getitem__` function to subset the data. See [this notebook](Example_Advanced_Data_Slicing.ipynb) for more in this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helping the Operators\n",
    "\n",
    "### describing the entries\n",
    "\n",
    "Operators can get inputs from many sources. Sometimes it can be helpful to get an idea of what is likely coming in.\n",
    "\n",
    "the `describe_entries` function returns a generator of `describe_feature` for each entry feature. It will crawl the graph backward when it encounters transformers or operators. If a loader did not implement `describe_feature` an empty dictionary will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kosh.operators.numpy_operator\n",
    "def my_operator(*data, **kargs):\n",
    "    return numpy.concatenate(*data)\n",
    "\n",
    "\n",
    "@kosh.transformers.numpy_transformer\n",
    "def my_transformer(data):\n",
    "    return data\n",
    "\n",
    "store = kosh.connect(\"demo_entries.sql\", delete_all_contents=True)\n",
    "ds = store.create()\n",
    "ds.associate(\"sample_files/run_000.hdf5\",\"hdf5\")\n",
    "c = ds.get_execution_graph(\"cycles\", transformers=my_transformer)\n",
    "double = my_operator(c, c)\n",
    "triple = my_operator(c, c, c)\n",
    "combine = my_operator(double, triple)\n",
    "mixed = my_operator(combine, combine)\n",
    "list(mixed.describe_entries())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting Input Datasets\n",
    "\n",
    "Similarly to their `describe_entries()` and the loaders' `get_requestor()` operators have a `get_input_datasets()` function that will return the datasets contributing to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KOSH DATASET\n",
       "\tid: 25ec9ee74c48465d92b94165c34711c9\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: moreno45\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: moreno45\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5 ( 6ccb39c0ba004f93b786b15774d381a8 )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       "--- Alias Feature Dictionary ---,\n",
       " KOSH DATASET\n",
       "\tid: 25ec9ee74c48465d92b94165c34711c9\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: moreno45\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: moreno45\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5 ( 6ccb39c0ba004f93b786b15774d381a8 )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       "--- Alias Feature Dictionary ---,\n",
       " KOSH DATASET\n",
       "\tid: 25ec9ee74c48465d92b94165c34711c9\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: moreno45\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: moreno45\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5 ( 6ccb39c0ba004f93b786b15774d381a8 )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       "--- Alias Feature Dictionary ---]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = ds[\"node/metrics_1\"]\n",
    "m2 = ds[\"node/metrics_2\"]\n",
    "m3 = ds[\"node/metrics_3\"]\n",
    "\n",
    "m1_2 = Add(m1, m2)\n",
    "m_f = Add(m3, m1_2)\n",
    "[x for x in m_f.get_input_datasets()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which in this case is not necessarily useful since all data come from the same dataset.\n",
    "\n",
    "### Requesting input loaders\n",
    "\n",
    "In the example above it might be more useful to access the loaders themselves (so we get the feature name and mime_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_3',\n",
       "  'hdf5'),\n",
       " ('/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_1',\n",
       "  'hdf5'),\n",
       " ('/g/g20/moreno45/Projects/ASCAML/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_2',\n",
       "  'hdf5')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.uri, x.feature, x._mime_type) for x in m_f.get_input_loaders()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these can be used by the operators themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "extract numpy\n",
      "['numpy']\n",
      "ADD INPUT DS: ['25ec9ee74c48465d92b94165c34711c9', '25ec9ee74c48465d92b94165c34711c9']\n",
      "INPUT FEATURES: ['node/metrics_1', 'node/metrics_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Add(kosh.KoshOperator):\n",
    "    types = {\"numpy\" : [\"numpy\",]}  # Our operator accepts numpy arrays and outputs numpy arrays\n",
    "    \n",
    "    def operate(self, *inputs, ** kargs):\n",
    "        # *inputs are the input received from their predecessors in the execution graph\n",
    "        # It is important to define **kargs as the function will receive `format=some_format`\n",
    "        datasets = list(self.get_input_datasets())\n",
    "        print(\"ADD INPUT DS:\", [x.id for x in datasets])\n",
    "        loaders = self.get_input_loaders()\n",
    "        print(\"INPUT FEATURES:\", [x.feature for x in loaders])\n",
    "        out = np.array(inputs[0])\n",
    "        for input_ in inputs[1:]:\n",
    "            out += np.array(input_)\n",
    "        return out\n",
    "mf = Add(ds[\"node/metrics_1\"], ds[\"node/metrics_2\"])[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-Norm Operator\n",
    "\n",
    "Kosh also comes with some built in operators. Here we will use the L-Norm Operator with some PyDV Curve Objects by associating an Ultra file to the dataset.\n",
    "\n",
    "```\n",
    ":returns:\n",
    "    - x (:py:class:`ndaray`) - The shared domain x-axis\n",
    "    - y0 (:py:class:`ndarray`) - The first shared domain interpolated y-axis\n",
    "    - y1 (:py:class:`ndarray`) - The second shared domain interpolated y-axis\n",
    "    - LNorm (:py:class:`float`) - The LNorm of the overlapping data points\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract numpy\n",
      "['numpy']\n",
      "(<HDF5 dataset \"my_dataset_xy\": shape (2, 50), type \"<f8\">,)\n",
      "{0: {'start_nodes': [('hdf5', <kosh.loaders.hdf5.HDF5Loader object at 0x7fff0ee99be0>, 0.20309757352107882)], 'end_nodes': [('numpy', None, 0.20309757352107882)]}, 1: {'start_nodes': [('ultra', <kosh.loaders.UltraLoader.UltraLoader object at 0x7fff0ee99880>, 0.40571904914574564)], 'end_nodes': [('curves', None, 0.40571904914574564), ('curves/pydv', None, 0.40571904914574564), ('curves/pdv', None, 0.40571904914574564), ('pydv', None, 0.40571904914574564), ('pdv', None, 0.40571904914574564), ('dict', None, 0.40571904914574564), ('numpy', None, 0.40571904914574564)]}}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs must be two 2-D Arrays [x0, y0], [xy, y1] or four 1-D arrays x0, y0, x1, y1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m ds\u001b[38;5;241m.\u001b[39massociate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_ult_file.ult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m                   mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multra\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m                   absolute_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 2 2-D Arrays\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x, y0, y1, LNormY \u001b[38;5;241m=\u001b[39m \u001b[43mkosh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKoshLNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy/values/my_dataset_xy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGaussian (a: 5.0 w: 5.0 c: 0.0)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                             \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Only overlap points, so no left, right, or period params needed for `numpy.interp()`\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/exec_graphs/core.py:317\u001b[0m, in \u001b[0;36mKoshExecutionGraph.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Very bare bone get item function\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    It is highly recommended to re-implement this.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Calls traverse then __getitem__ on the result of traverse\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    :param key: key to access\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    :type key: object (usually int, slice or str)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__getitem_key__\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/exec_graphs/core.py:371\u001b[0m, in \u001b[0;36mKoshExecutionGraph.traverse\u001b[0;34m(self, format, *args, **kargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         out\u001b[38;5;241m.\u001b[39madd_edge(node, pth[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# We can now travel back the pth to obtain\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# the data.\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/exec_graphs/core.py:425\u001b[0m, in \u001b[0;36mKoshExecutionGraph._operate\u001b[0;34m(self, graph, node, output_format, **kargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     kargs2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem_key__\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_res:\n\u001b[0;32m--> 425\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mprev\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkargs2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m getitem_key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    427\u001b[0m         res \u001b[38;5;241m=\u001b[39m res[getitem_key]\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/exec_graphs/core.py:434\u001b[0m, in \u001b[0;36mKoshExecutionGraph._operate\u001b[0;34m(self, graph, node, output_format, **kargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperate_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 434\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperate_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/operators/core.py:85\u001b[0m, in \u001b[0;36mKoshOperator.operate_\u001b[0;34m(self, *inputs, **kargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(signature, result)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Projects/ASCAML/kosh/kosh/operators/koshMaths.py:103\u001b[0m, in \u001b[0;36mKoshLNorm.operate\u001b[0;34m(self, *inputs, **kargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     features[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my-axis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs must be two 2-D Arrays [x0, y0], [xy, y1] or four 1-D arrays x0, y0, x1, y1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Acquire common domain\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverlap_only\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs must be two 2-D Arrays [x0, y0], [xy, y1] or four 1-D arrays x0, y0, x1, y1"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "h5file = h5py.File('myfile.hdf5', 'w')\n",
    "grp = h5file.create_group(\"my/values\")\n",
    "x0_dset = np.linspace(-14, 14)\n",
    "y0_dset = np.sin(x0_dset)\n",
    "x1_dset = np.linspace(-15, 15)\n",
    "y1_dset = np.cos(x1_dset)\n",
    "\n",
    "# XY Paired\n",
    "grp.create_dataset(\"my_dataset_xy\", data=np.array([x0_dset, y0_dset]))\n",
    "\n",
    "# XY Separated\n",
    "grp.create_dataset(\"my_dataset_x0\", data=x0_dset)\n",
    "grp.create_dataset(\"my_dataset_y0\", data=y0_dset)\n",
    "grp.create_dataset(\"my_dataset_x1\", data=x1_dset)\n",
    "grp.create_dataset(\"my_dataset_y1\", data=y1_dset)\n",
    "\n",
    "ds.associate('myfile.hdf5',\n",
    "                  mime_type=\"hdf5\",\n",
    "                  absolute_path=False)\n",
    "\n",
    "# ultra\n",
    "ds.associate(\"my_ult_file.ult\",\n",
    "                  mime_type=\"ultra\",\n",
    "                  absolute_path=False)\n",
    "\n",
    "# 2 2-D Arrays\n",
    "x, y0, y1, LNormY = kosh.operators.KoshLNorm(ds[\"my/values/my_dataset_xy\"][:],\n",
    "                                             ds['Gaussian (a: 5.0 w: 5.0 c: 0.0)'],\n",
    "                                             \n",
    "                                             power=1, left=None, right=None, period=None)[:]\n",
    "\n",
    "print(x)\n",
    "\n",
    "# Only overlap points, so no left, right, or period params needed for `numpy.interp()`\n",
    "x, y0, y1, LNormY = kosh.operators.KoshLNorm(ds['Gaussian (a: 5.0 w: 5.0 c: 0.0)'],\n",
    "                                             ds[\"my/values/my_dataset_xy\"],\n",
    "                                             power=1, overlap_only=True)[:]\n",
    "\n",
    "print(x)\n",
    "\n",
    "# 4 1-D Arrays\n",
    "x, y0, y1, LNormY = kosh.operators.KoshLNorm(ds[\"my/values/my_dataset_x0\"],\n",
    "                                             ds[\"my/values/my_dataset_y0\"],\n",
    "                                             ds[\"my/values/my_dataset_x1\"],\n",
    "                                             ds[\"my/values/my_dataset_y1\"],\n",
    "                                             power=1, left=None, right=None, period=None)[:]\n",
    "\n",
    "print(x)\n",
    "\n",
    "# Only overlap points, so no left, right, or period params needed for `numpy.interp()`\n",
    "x, y0, y1, LNormY = kosh.operators.KoshLNorm(ds[\"my/values/my_dataset_x0\"],\n",
    "                                             ds[\"my/values/my_dataset_y0\"],\n",
    "                                             ds[\"my/values/my_dataset_x1\"],\n",
    "                                             ds[\"my/values/my_dataset_y1\"],\n",
    "                                             power=1, overlap_only=True)[:]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kosh-dev",
   "language": "python",
   "name": "kosh-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
