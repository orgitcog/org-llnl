{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "**For more examples of what Kosh can do visit [GitHub Examples](https://github.com/LLNL/kosh/tree/stable/examples).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kosh\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "store = kosh.connect(\"my_store.sqlite\", delete_all_contents=True)\n",
    "print(\"Kosh is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "As mentioned in the `README.md`, the data we will be using is [Optical Recognition of Handwritten Digits](https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits). Luckily, Scikit-Learn has pre-processed that data and made it easily accesible via its [Toy Datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html). We will use [`sklearn.datasets.load_digits()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) which returns a dictionary-like structure that can be seen below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits() \n",
    "for key, val in digits.items():\n",
    "    print(f\"----- {key} -----\")\n",
    "    print(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Images\n",
    "\n",
    "However, in order to show how Kosh can load different types of data, we will first convert the arrays of image data from [`sklearn.datasets.load_digits()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) into images to use Kosh's Loaders. Loaders in Kosh allow the user (as the name suggests) to load any type of data they want via what is called \"associating\" a file to a Kosh Dataset. Kosh comes with a set of built-in Loaders (see [Example_02_Read_Data.ipynb](https://github.com/LLNL/kosh/blob/stable/examples/Example_02_Read_Data.ipynb)) but a user can create custom ones (see [Example_Custom_Loader.ipynb](https://github.com/LLNL/kosh/blob/stable/examples/Example_Custom_Loader.ipynb)). It is important to note that the Kosh database doesn't actually store any of the data when you associate a file, it just references the file. If the associated file is deleted, the data will no longer be \"in\" the Kosh database. You can create a dataset for each file or associate multiple files to one dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "for i, image in enumerate(digits['images']):\n",
    "    temp_image = Image.fromarray(image.astype(np.uint8))\n",
    "    if i == 0:\n",
    "        plt.imshow(temp_image, cmap='gray')\n",
    "    temp_image.save(f'images/image_{i}.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Kosh Dataset\n",
    "\n",
    "We create our Kosh Dataset and add whatever metadata we want. The metadata (which end up being dataset attributes) can later be used to find and filter specific datasets. See [kosh/examples/Example_Simulation_Workflow.ipynb](https://github.com/LLNL/kosh/blob/stable/examples/Example_Simulation_Workflow.ipynb) for more information on how to add metadata, update it, and extract it.\n",
    "\n",
    "We add metadata that is in the `DESCR` of `sklearn.datasets.load_digits()`. Note that `id`, `name` and `creator` are special named Kosh Dataset attributes. The attributes of a dataset can be seen with `dataset.list_attributes()` and extracted via `dataset.MY_ATTRIBUTE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy paste from digits['DESCR']\n",
    "# print(digits['DESCR'])\n",
    "\n",
    "metadata = {\"name\": \"Optical recognition of handwritten digits dataset\",  # 'name' is a special named Kosh attribute for name of Kosh Dataset\n",
    "            \"Number of Instances\": 1797,\n",
    "            \"Number of Attributes\": 64,\n",
    "            \"Attribute Information\": \"8x8 image of integer pixels in the range 0..16.\",\n",
    "            \"Missing Attribute Values\": None,\n",
    "            \"Creator\": \"E. Alpaydin (alpaydin '@' boun.edu.tr)\", # 'creator' is a special named Kosh attribute for creator of Kosh dataset\n",
    "            \"Date\": \"July; 1998\"}\n",
    "            \n",
    "  \n",
    "dataset = store.create(metadata=metadata)\n",
    "\n",
    "print(\"BEFORE ASSOCIATING DATA:\\n\\n\", dataset)\n",
    "\n",
    "print('\\n\\nAttributes:\\n\\n')\n",
    "print(dataset.list_attributes())\n",
    "print(getattr(dataset, 'Attribute Information'))\n",
    "print(dataset.Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating Data\n",
    "\n",
    "Here we will be associating all the pngs to a single Kosh Dataset so we can use the `dataset.to_dataframe()` method. As discussed in the Ball Bounce Metadata Machine Learning tutorial, each dataset can have its own metadata attributes but you can also add metadata attributes to each associated file within each dataset. We can extract all the attributes for all associated files in a Kosh Dataset into a Pandas DataFrame using `dataset.to_dataframe()`. By default this dataframe will always have the `id`, `mime_type`, `uri`, and `associated` columns.\n",
    "\n",
    "When a user associates a file to a dataset, the data in the file now becomes a Kosh Dataset feature. The features of a dataset can be seen with `dataset.list_features()` and extracted via `dataset['MY_FEATURE'][:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, target in enumerate(digits['target']):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Image {i+1} of {len(digits['target'])}\")\n",
    "    temp_image_path = f'images/image_{i}.png'\n",
    "    metadata={\"label\": int(target)}  # int or float type\n",
    "    dataset.associate(temp_image_path,\n",
    "                      metadata=metadata,\n",
    "                      mime_type=\"png\")  # mime_type is what determins which Kosh loader to use\n",
    "    \n",
    "print(\"AFTER ASSOCIATING DATA:\\n\\n\", dataset)\n",
    "\n",
    "\n",
    "df = dataset.to_dataframe()\n",
    "print(\"\\n\\nPANDAS DATAFRAME:\\n\\n\", df)\n",
    "\n",
    "\n",
    "print('\\n\\nFeatures:\\n\\n')\n",
    "print(dataset.list_features())\n",
    "print(dataset['image_@_/g/g20/moreno45/Projects/WEAVE/weave_docs/docs/tutorials/Public/digit_classification/images/image_0.png'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data\n",
    "\n",
    "We will extract our features and labels of interest from the dataframe above since `dataset.to_dataframe()` also includes other metadata by default. The features will be each of the 8 x 8 = 64 pixels in the image and the label will be the actual number of the image. We use SciKit Learn's `train_test_split()` method to split the data into train, validation, and test data.\n",
    "\n",
    "No need to scale the data since all pixel values have the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting image data Kosh feature into a column\n",
    "df['image_data'] = df.apply(lambda row: np.array(Image.open(row[\"uri\"])).ravel(), axis=1) \n",
    "print(\"\\n\\nDataframe with image_data:\\n\\n\",df)\n",
    "\n",
    "# List comprehension since each row of 'image_data' is an array itself\n",
    "reshaped = np.array([array for array in df['image_data'].values]).reshape(-1, len(digits['feature_names']))\n",
    "\n",
    "df_original = pd.DataFrame(reshaped, columns=digits['feature_names'])\n",
    "df_original['label'] = df['label']\n",
    "print(\"\\n\\nMachine Learning Dataframe:\\n\\n\", df_original)\n",
    "\n",
    "df_original_features = df_original[digits['feature_names']].copy()\n",
    "df_original_labels = df_original['label'].copy()\n",
    "\n",
    "\n",
    "# Splitting data\n",
    "df_train_features, df_test_features, df_train_labels, df_test_labels = train_test_split(df_original_features, df_original_labels, test_size=0.2, random_state=42)\n",
    "df_train_features, df_validation_features, df_train_labels, df_validation_labels = train_test_split(df_train_features, df_train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(df_train_features.head())\n",
    "\n",
    "print(f\"Train Size features: {df_train_features.shape} and labels: {df_train_labels.shape}\")\n",
    "print(f\"Validation Size features: {df_validation_features.shape} and labels: {df_validation_labels.shape}\")\n",
    "print(f\"Test Size features: {df_test_features.shape} and labels: {df_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning Pandas DataFrames into Matricies\n",
    "\n",
    "Now we will convert our Pandas DataFrames into matricies so the Machine Learning algorithms can process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train_features.to_numpy()\n",
    "y_train = df_train_labels.to_numpy()\n",
    "\n",
    "X_validation = df_validation_features.to_numpy()\n",
    "y_validation = df_validation_labels.to_numpy()\n",
    "\n",
    "X_test = df_test_features.to_numpy()\n",
    "y_test = df_test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Model\n",
    "\n",
    "We will now train our model using `sklearn.linear_model.LogisticRegression()` by using `sklearn.linear_model.LogisticRegression.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(max_iter=int(1e6))\n",
    "LogReg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Confusion Matrix\n",
    "\n",
    "Now that our model is trained, we can calculate the score which is just the mean accuracy `sklearn.linear_model.LogisticRegression.score()` for our train, validation, and test data. We can also see what the model will infer/predict using `sklearn.linear_model.LogisticRegression.predict()` and plot them via the confusion matrix `sklearn.metrics.confusion_matrix()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Train Mean Accuracy:\", LogReg.score(X_train, y_train))\n",
    "print(\"Validation Mean Accuracy:\", LogReg.score(X_validation, y_validation))\n",
    "print(\"Test Mean Accuracy:\", LogReg.score(X_test, y_test))\n",
    "\n",
    "print(f'Train Prediction {LogReg.predict(X_train[-1].reshape(1,-1))[0]} and actual value {y_train[-1]}')\n",
    "print(f'Validation Prediction {LogReg.predict(X_validation[-1].reshape(1,-1))[0]} and actual value {y_validation[-1]}')\n",
    "print(f'Test Prediction {LogReg.predict(X_test[-1].reshape(1,-1))[0]} and actual value {y_test[-1]}')\n",
    "\n",
    "for X, y, data_type in zip([X_train, X_validation, X_test],\n",
    "                           [y_train, y_validation, y_test],\n",
    "                           ['Train_Data', 'Validation_Data', 'Test_Data']):\n",
    "                \n",
    "    predictions = LogReg.predict(X)\n",
    "    cm = confusion_matrix(y, predictions, labels=LogReg.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=LogReg.classes_)\n",
    "    disp.plot()\n",
    "    plt.title(data_type)\n",
    "    plt.savefig(f'{data_type}_confusion_matrix.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave-demos",
   "language": "python",
   "name": "weave-demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
