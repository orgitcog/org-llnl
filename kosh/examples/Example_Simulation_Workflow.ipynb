{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05389728-e44f-4da5-aceb-883e93e57544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kosh\n",
    "from sina.utils import DataRange, has_all, has_any, all_in, any_in\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538c29d-ce73-4952-af90-9bcf3f852620",
   "metadata": {},
   "source": [
    "# Simulation Workflow\n",
    "\n",
    "This notebook will take a user through a simple simulation workflow with an inner loop (single simulations) and outer loop (grouping simulations into an ensemble)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96cc8f-e033-4adf-8f77-5669d872746b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Overall Store\n",
    "\n",
    "This will house all the simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e04de6-711c-4bdc-860a-2d4e8afe7b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/moreno45/Projects/ASCAML/kosh/kosh/utils.py:522: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "store_path = 'my_store.sqlite' # \"/usr/workspace/group_dir/group.sqlite\"\n",
    "try:\n",
    "    os.remove(store_path)\n",
    "except:\n",
    "    pass\n",
    "store = kosh.connect(store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955de48-d9ef-44b7-bfa2-7bdd108de6c2",
   "metadata": {},
   "source": [
    "## Inner Loop\n",
    "\n",
    "This inner loop contains the data for the individual simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece25383-08ac-4545-b7f3-5e6b54c35c57",
   "metadata": {},
   "source": [
    "### Create Dataset for a Simulation\n",
    "\n",
    "We create our first dataset and add `metadata` to it which can be used to filter datasets using the `store.find()` method later on. These are single value items and are dataset attributes.\n",
    "\n",
    "See [Example_00_Open_Store_And_Add_Datasets.ipynb](Example_00_Open_Store_And_Add_Datasets.ipynb) for more examples on how to add data. \n",
    "\n",
    "See [Example_04_Schemas.ipynb](Example_04_Schemas.ipynb) for examples on how to set up a schema for the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4814c649-c9b2-46a5-a61b-f45fe998683b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Scratch:\n",
      " KOSH DATASET\n",
      "\tid: d0996640cf2d438c8e6e4c8949ae0575\n",
      "\tname: My Example Dataset From Scratch\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: My Example D... From Scratch\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary --- \n",
      "\n",
      "From Sina Record:\n",
      " KOSH DATASET\n",
      "\tid: d0996640cf2d438c8e6e4c8949ae0575\n",
      "\tname: My Example Dataset From Scratch\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tmachine: Catalyst\n",
      "\tmode: standard\n",
      "\tname: My Example D... From Scratch\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "\tstart_time: 0\n",
      "\ttotal_energy: 18.8\n",
      "--- Associated Data (1)---\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( quick_sample )\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary --- \n",
      "\n",
      "From Pandas:\n",
      " KOSH DATASET\n",
      "\tid: 57e8a2e6df3e44a68d675977e91712ba_0\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tD: Lassen\n",
      "\tmode: high-def\n",
      "\tstart_time: 0.4449736400815272\n",
      "\ttotal_energy: 23.6\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary --- \n",
      "\n",
      "From CSV:\n",
      " KOSH DATASET\n",
      "\tid: c40699ca067a4e29ba0f25470cf29e57\n",
      "\tname: new_dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tUnnamed: 0: 0.0\n",
      "\tcreator: moreno45\n",
      "\tmynewattribute: 5.0\n",
      "\tmyotherattribute: None\n",
      "\tmyparam10: None\n",
      "\tmyparam20: None\n",
      "\tmyparam30: None\n",
      "\tmyparam40: None\n",
      "\tmyparam50: None\n",
      "\tmyparam60: None\n",
      "\tname: new_dataset\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary --- \n",
      "\n",
      "From Sina HDF5:\n",
      " KOSH DATASET\n",
      "\tid: 281bdb406b99412880af991e9dd77047_0\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\t data_type:  test\n",
      "\t my_other_att: 23.0\n",
      "\t passed:  True\n",
      "\t tempF: 99.0\n",
      "\tatt_1: 5.0\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary --- \n",
      "\n",
      "From Sina JSON:\n",
      " KOSH DATASET\n",
      "\tid: obj1\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 3.3\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "--- Associated Data (2)---\n",
      "\tMime_type: image/png\n",
      "\t\tfoo.png ( obj1 )\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( timeplot_1 )\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# From scratch #\n",
    "################\n",
    "# important attributes/metadata that can be used in store.find() method later\n",
    "my_metadata ={'param4': 1,\n",
    "              'param5': 'test',\n",
    "              'param6': 3.14}\n",
    "\n",
    "dataset_from_scratch = store.create(name='My Example Dataset From Scratch', # name to find dataset later on\n",
    "                                    metadata=my_metadata)\n",
    "\n",
    "print(\"From Scratch:\\n\", dataset_from_scratch, \"\\n\")\n",
    "\n",
    "######################################################\n",
    "# You can also import a dataset from various formats #\n",
    "######################################################\n",
    "\n",
    "#########################\n",
    "# Sina Record object(s) #\n",
    "#########################\n",
    "import sina\n",
    "from sina.model import CurveSet\n",
    "\n",
    "possible_mode = [\"quick\", \"standard\", \"test\", \"high-def\"]\n",
    "possible_machine = [\"Quartz\", \"Catalyst\", \"local\", \"Sierra\", \"Lassen\", \"Ruby\"]\n",
    "\n",
    "record = sina.model.Record(id=\"sina_rec_0\", type=\"foo_type\")\n",
    "record.add_data('total_energy', random.randint(0, 1000) / 10.0)\n",
    "record.add_data('start_time', 0)\n",
    "record.add_data('mode', random.choice(possible_mode))\n",
    "record.add_data('machine', random.choice(possible_machine))\n",
    "\n",
    "cs1 = CurveSet(\"quick_sample\")\n",
    "cs1.add_independent(\"time\", [1, 2, 3, 4])\n",
    "cs1.add_dependent(\"local_density\", random.sample(range(1, 10), 4))\n",
    "cs1.add_dependent(\"est_overall_density\", random.sample(range(1, 10), 4))\n",
    "record.add_curve_set(cs1)\n",
    "\n",
    "datasets_from_sina_record = store.import_dataset(record)\n",
    "\n",
    "print(\"From Sina Record:\\n\", datasets_from_sina_record[0], \"\\n\")\n",
    "\n",
    "####################\n",
    "# Pandas DataFrame #\n",
    "####################\n",
    "import pandas as pd\n",
    "\n",
    "num_rows = 10\n",
    "\n",
    "# Each row is a dataset and each column is an attribute/metadata\n",
    "# if there is no 'id' column it will randomly give each dataset one using uuid.uuid4().hex\n",
    "data = {\n",
    "    'total_energy': np.random.randint(0, 1000, size=num_rows) / 10.0,\n",
    "    'start_time': np.random.rand(num_rows),\n",
    "    'mode': np.random.choice(possible_mode, size=num_rows),\n",
    "    'D': np.random.choice(possible_machine, size=num_rows)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "datasets_from_pandas = store.import_dataset(df, match_attributes=['id'])  # This is a list of datasets if more than one row\n",
    "\n",
    "print(\"From Pandas:\\n\", datasets_from_pandas[0][0], \"\\n\")\n",
    "\n",
    "############\n",
    "# CSV File #\n",
    "############\n",
    "# Each row is a dataset and each column is an attribute/metadata\n",
    "# if there is no 'id' column it will randomly give each dataset one using uuid.uuid4().hex\n",
    "datasets_from_csv = store.import_dataset(\"../tests/baselines/csv/my_csv_file.csv\")  # This is a list of datasets if more than one row\n",
    "\n",
    "print(\"From CSV:\\n\", datasets_from_csv[0][0], \"\\n\")\n",
    "\n",
    "#############\n",
    "# Sina HDF5 #\n",
    "#############\n",
    "# There can be multiple records in a single hdf5\n",
    "datasets_from_sina_hdf5 = store.import_dataset(\"sina_rec.hdf5\",\n",
    "                                         match_attributes=['id'])\n",
    "print(\"From Sina HDF5:\\n\", datasets_from_sina_hdf5[0], \"\\n\")\n",
    "\n",
    "#############\n",
    "# Sina JSON #\n",
    "#############\n",
    "dataset = store.import_dataset(\"sina_curve_rec.json\",\n",
    "                               match_attributes=['id'])[0]\n",
    "\n",
    "for key, val in my_metadata.items():\n",
    "        setattr(dataset, key, val)\n",
    "\n",
    "# The `metadata` will be in the attributes\n",
    "# The sina record already has some metadata pre-populated\n",
    "# It also has some associated data which will be discussed in the upcoming sections\n",
    "print(\"From Sina JSON:\\n\",dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579972aa-a36b-450f-a287-2c623de47abe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adding Data to a Dataset\n",
    "\n",
    "You can also add time history data to the dataset. Each time history data is grouped into `curve_sets` with one `independent` curve and one or more `dependent` curves.\n",
    "\n",
    "See [Example_01_Add_Data_To_Datasets.ipynb](Example_01_Add_Data_To_Datasets.ipynb) for more examples on how to add curve sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b418312-51c9-4fd9-b7e1-531e1a6d40bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: obj1\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 3.3\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "\tsome_variable_mean: 4.7749999999999995\n",
      "--- Associated Data (2)---\n",
      "\tMime_type: image/png\n",
      "\t\tfoo.png ( obj1 )\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( timeplot_1, my_curves, my_other_curves )\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "# dataset.add_curve(np.array(my_array).tolist(), 'my_time_series', 'x_pos')\n",
    "dataset.add_curve([1,2,3,4], \"my_curves\", \"time\")\n",
    "dataset.add_curve([2.3, 3.4, 5.6, 7.8], \"my_curves\", \"some_variable\")\n",
    "dataset.add_curve([3, 4,5], \"my_other_curves\", \"time\")\n",
    "\n",
    "# Adding a single value to the metadata\n",
    "some_variable_mean = float(np.mean(dataset['my_curves/some_variable'][:]))\n",
    "setattr(dataset, 'some_variable_mean', some_variable_mean)\n",
    "\n",
    "# The `curve_sets` are located in the associated data section as `mime_type=\"sina/curve\"`.\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02066b77-5e24-448f-a46b-8b58fe9ecb40",
   "metadata": {},
   "source": [
    "### Associate Data to a Dataset\n",
    "\n",
    "Associating data to a dataset means that you can reference that file and its data. The dataset doesn't store any of the data when you associate a file, it just references the file which means if the associated file is deleted, the data will no longer be \"in\" the dataset.\n",
    "\n",
    "Below are a couple of common file formats and how to associate them to the correct `loader` through the `mime_type` so Kosh knows how to access the data. See [Example_02_Read_Data.ipynb](Example_02_Read_Data.ipynb) for more examples on how to associate data. \n",
    "\n",
    "If there is a file format that is not supported by Kosh, you can create your own custom loader [Example_Custom_Loader.ipynb](Example_Custom_Loader.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25b0109-a6da-4059-ab54-50d0ae19cf44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: obj1\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 3.3\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "\tsome_variable_mean: 4.7749999999999995\n",
      "--- Associated Data (5)---\n",
      "\tMime_type: hdf5\n",
      "\t\t../tests/baselines/node_extracts2/node_extracts2.hdf5 ( b8a7bd3c354f4af0b2b612b87895a389 )\n",
      "\tMime_type: image/png\n",
      "\t\tfoo.png ( obj1 )\n",
      "\tMime_type: pandas/csv\n",
      "\t\t../tests/baselines/csv/my_csv_file.csv ( 6a2390092c3f42fb96a869c67baa1fdc )\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( timeplot_1, my_curves, my_other_curves )\n",
      "\tMime_type: ultra\n",
      "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult ( 5aa6593ccfa749b29c50be6feb91be8f )\n",
      "--- Ensembles (0)---\n",
      "\t[]\n",
      "--- Ensemble Attributes ---\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "dataset.associate(\"../tests/baselines/node_extracts2/node_extracts2.hdf5\",\n",
    "                  mime_type=\"hdf5\",\n",
    "                  metadata={\"param10\": \"my value\",\n",
    "                            \"my other param\": \"Example Text\"},\n",
    "                  absolute_path=False)\n",
    "\n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you can pass in its arguments through `loader_kwargs`\n",
    "dataset.associate(\"../tests/baselines/csv/my_csv_file.csv\",\n",
    "                  mime_type=\"pandas/csv\",\n",
    "                  metadata={\"param20\": \"my other value\",\n",
    "                            \"my param\": 10},\n",
    "                  loader_kwargs={'index_col': 0},\n",
    "                  absolute_path=False)\n",
    "\n",
    "# ultra\n",
    "dataset.associate(\"my_ult_file.ult\",\n",
    "                  metadata={\"param30\": 45,\n",
    "                            \"my param\": 560},\n",
    "                  mime_type=\"ultra\")\n",
    "\n",
    "# These will show up in associated data with their correspondign `mime_type`\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd9eae-24a5-461e-8781-52efbee874ac",
   "metadata": {},
   "source": [
    "### Available Data\n",
    "\n",
    "The commands below allow a user to see what data is available in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727bb351-6b67-4f06-a5ac-0d537c1deee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes:\n",
      "\t ['id', 'param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'some_variable_mean']\n",
      "\n",
      "\n",
      "Features Sets:\n",
      "\t ['my_curves', 'my_curves/some_variable', 'my_curves/time', 'my_other_curves', 'my_other_curves/time', 'timeplot_1', 'timeplot_1/feature_a', 'timeplot_1/feature_b', 'timeplot_1/time', 'cycles', 'direction', 'elements', 'node', 'node/metrics_0', 'node/metrics_1', 'node/metrics_10', 'node/metrics_11', 'node/metrics_12', 'node/metrics_2', 'node/metrics_3', 'node/metrics_4', 'node/metrics_5', 'node/metrics_6', 'node/metrics_7', 'node/metrics_8', 'node/metrics_9', 'zone', 'zone/metrics_0', 'zone/metrics_1', 'zone/metrics_2', 'zone/metrics_3', 'zone/metrics_4', 'id', 'name', 'creator', 'mynewattribute', 'myotherattribute', 'myparam10', 'myparam20', 'myparam30', 'myparam40', 'myparam50', 'myparam60', 'Gaussian (a: 5.0 w: 5.0 c: 0.0)', 'Gaussian (a: 5.0 w: 5.0 c: 50.0)', 'A + B', 'Straight Line (m: 0.125 b: -2.5 xmin: 60.0 xmax: 40.0)', 'a.y+numpy.random.normal(size=100)', 'E + B', 'Gaussian (a: 10.0 w: 5.0 c: 70.0)', 'g.y+numpy.random.normal(size=500)+70', 'F + H', 'Gaussian (a: 20.0 w: 5.0 c: 20.0)', 'j.y+numpy.random.normal(size=50)+20', 'I + K', 'Gaussian (a: 20.0 w: 1.0 c: 50.0)', 'm.y+numpy.random.normal(size=500)+50', 'L + N', 'Gaussian (a: 50.0 w: 0.25 c: 10.0)', 'p.x+numpy.random.normal(size=200)', 'P + Q', 'O + R', 'A + D']\n"
     ]
    }
   ],
   "source": [
    "print('Attributes:') # can be single value or list\n",
    "print('\\t',dataset.list_attributes())\n",
    "print('\\n')\n",
    "print('Features Sets:')  # only for time history data\n",
    "print('\\t',dataset.list_features())\n",
    "\n",
    "# If there are a lot of files and features, use_cache=True can be used\n",
    "# so that Kosh doesn't have to search through all the files again\n",
    "# print('\\t',dataset.list_features(use_cache=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0173a0-0ca0-4f6c-afb9-3e23e33a7f3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accessing Data\n",
    "\n",
    "Kosh knows which data is located in which file so all the user has to do is call the feature name to acquire that data. You can post-process this data and add it to the dataset through `setattr()` or `dataset.add_curve()`.\n",
    "\n",
    "See [Example_05a_Transformers.ipynb](Example_05a_Transformers.ipynb), [Example_05b_Transformers-SKL.ipynb](Example_05b_Transformers-SKL.ipynb), and [Example_05b_Transformers-SKL.ipynb](Example_05b_Transformers-SKL.ipynb) on more ways to post process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ad452-7270-4b0e-a81a-2601f2771518",
   "metadata": {},
   "source": [
    "#### Whole File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e04c6d-42e6-4781-9549-34e98c8dabaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5\n",
      "<HDF5 file \"node_extracts2.hdf5\" (mode r)> \n",
      "\n",
      "\n",
      "CSV\n",
      "                                  id          name  \\\n",
      "0   c40699ca067a4e29ba0f25470cf29e57   new_dataset   \n",
      "1   21ef0cd592d24c5c8fcc89b066fb7418            15   \n",
      "2   f970bd06a67a4956bd475fc48bd5a214             8   \n",
      "3   3a79fc992f664a88a08151826f352cdf  new_dataset2   \n",
      "4   6c35fb8c25034483af7031fada507062            16   \n",
      "5   b634fce83dfd4e73b1f7f92c43b5ee1d             7   \n",
      "6   1c14f05f44d846499b390fd435827f7d             2   \n",
      "7   95d16b109ab64c6680af6f0bdc02aa00             9   \n",
      "8   c0215e9c4080430da59979f71009c045            14   \n",
      "9   b1e66c735ac6483d88fe041ab70dab2c             0   \n",
      "10  4b77902d818a4980b8e55ad2106cd73e            21   \n",
      "11  8554af7b60a34492a202a5f6fd468da1             5   \n",
      "12  f05a324c3693494b8d0692ee6fd4b4bc             4   \n",
      "13  ea0e89d9cb9a476d8f6dd683e8fc2666             1   \n",
      "14  c941ee7ecd0a48b48ef6c3bad13c0216            11   \n",
      "15  50677728c8dd4844b54f179ea23f09cf            10   \n",
      "16  373fbc3883504fcb92c9b9c72f0df5e2            22   \n",
      "17  911fe76680924f6586ae1f8d83497acc            13   \n",
      "18  23cecefa740346d8970bca303ce0f38b            19   \n",
      "19  bc49e56b071343d79f19edc5f418059a             6   \n",
      "20  99b85007021f4938a1b40fa2ed8fd6b3            12   \n",
      "21  bfabd6cb17224322ae5513097932fbe7             3   \n",
      "22  78d1f6bd9e024585b67eca81cbb68dac            17   \n",
      "23  f03bfb80e755442bb59e46da9038aa3b            18   \n",
      "24  a61f2476253d4e64ad98463742d578e2            20   \n",
      "\n",
      "                             creator  mynewattribute  myotherattribute  \\\n",
      "0   9b7d60f394284459a1ae979bb0af019f             5.0               NaN   \n",
      "1   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "2   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "3   9b7d60f394284459a1ae979bb0af019f             NaN              10.0   \n",
      "4   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "5   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "6   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "7   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "8   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "9   9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "10  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "11  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "12  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "13  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "14  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "15  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "16  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "17  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "18  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "19  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "20  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "21  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "22  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "23  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "24  9b7d60f394284459a1ae979bb0af019f             NaN               NaN   \n",
      "\n",
      "    myparam10  myparam20  myparam30  myparam40  myparam50 myparam60  \n",
      "0         NaN        NaN        NaN        NaN        NaN       NaN  \n",
      "1    1.279276   0.396805   4.996078   0.950918   1.544344         D  \n",
      "2    1.743174   1.052443   4.636964   2.270797   0.109443         U  \n",
      "3         NaN        NaN        NaN        NaN        NaN       NaN  \n",
      "4    0.144626   1.168135   4.131349   2.466016   1.708542         U  \n",
      "5    1.382974   0.369745   3.904778   0.020335   2.218738         S  \n",
      "6    0.051635   0.106066   0.858589   1.064911   2.274851         [  \n",
      "7    1.391787   0.463967   0.086163   0.108305   1.174103         Z  \n",
      "8    0.289573   1.109298   1.415927   1.364071   0.631254         Z  \n",
      "9    0.294249   1.180731   2.355948   0.686090   1.978185         U  \n",
      "10   1.079470   0.358233   1.128227   2.985315   1.507420         H  \n",
      "11   1.914257   0.161840   4.702574   0.454322   0.866904         T  \n",
      "12   0.396960   1.349371   4.109795   0.371130   1.372740         S  \n",
      "13   1.513962   1.303810   2.476925   0.709315   0.804382         P  \n",
      "14   0.295615   1.082137   1.324409   2.333544   0.073743         N  \n",
      "15   1.340525   0.322456   4.356252   2.803816   0.935973         I  \n",
      "16   0.026997   0.740502   0.230570   2.337639   2.093349         P  \n",
      "17   1.795573   0.502343   1.138907   2.264304   0.623987         D  \n",
      "18   0.664151   0.686475   3.616309   1.470181   0.014480         J  \n",
      "19   1.176025   0.205264   2.755670   2.899851   0.385364         W  \n",
      "20   1.501699   0.919065   1.748989   1.566512   0.263774         X  \n",
      "21   1.366581   0.172806   2.916254   2.970164   2.332836         Y  \n",
      "22   1.579366   0.743700   3.498894   2.014768   1.320781         T  \n",
      "23   0.819499   0.267500   4.649124   2.752715   1.928142         O  \n",
      "24   0.204605   0.062233   2.194800   0.826005   1.347044         R   \n",
      "\n",
      "\n",
      "ULTRA\n",
      "[<curve.Curve object at 0x1554d3be4820>, <curve.Curve object at 0x1554d3be4e20>, <curve.Curve object at 0x1554d3be4970>, <curve.Curve object at 0x1554d3be4370>, <curve.Curve object at 0x1554d3be4d60>, <curve.Curve object at 0x1554d3be4fa0>, <curve.Curve object at 0x1554d3be4dc0>, <curve.Curve object at 0x1554d3be4d90>, <curve.Curve object at 0x1554d3be71c0>, <curve.Curve object at 0x1554d3be4e50>, <curve.Curve object at 0x1554d3be4df0>, <curve.Curve object at 0x1554d3be7310>, <curve.Curve object at 0x1554d3be7040>, <curve.Curve object at 0x1554d3be4e80>, <curve.Curve object at 0x1554d3be7520>, <curve.Curve object at 0x1554d3be4fd0>, <curve.Curve object at 0x1554d3be7130>, <curve.Curve object at 0x1554d3be72e0>, <curve.Curve object at 0x1554d3be75b0>, <curve.Curve object at 0x1554d3be7370>] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "associated_hdf5 = list(dataset.find(mime_type=\"hdf5\"))[0]\n",
    "h5_file = dataset.open(Id=associated_hdf5.id)\n",
    "print('HDF5')\n",
    "print(h5_file,'\\n\\n')\n",
    "\n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you will get a `pandas.DataFrame()`\n",
    "associated_csv_pandas = list(dataset.find(mime_type=\"pandas/csv\"))[0]\n",
    "df = dataset.open(Id=associated_csv_pandas.id)\n",
    "print('CSV')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# ultra\n",
    "# returns a list with PyDV curve objects where data is in curve.x and curve.y see curve.__dict__ for more info\n",
    "associated_ultra = list(dataset.find(mime_type=\"ultra\"))[0]\n",
    "ultra = dataset.open(Id=associated_ultra.id)\n",
    "print('ULTRA')\n",
    "print(ultra,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0bbcd9-5fbc-48b3-8b36-d14d74da461c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9c0dd3-ed2d-4d6b-a762-e56fedf9db11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5\n",
      "[<HDF5 dataset \"metrics_5\": shape (2, 18), type \"<f4\">, <HDF5 dataset \"metrics_11\": shape (2, 18), type \"<f4\">] \n",
      "\n",
      "\n",
      "CSV\n",
      "                             creator  myparam40\n",
      "0   9b7d60f394284459a1ae979bb0af019f        NaN\n",
      "1   9b7d60f394284459a1ae979bb0af019f   0.950918\n",
      "2   9b7d60f394284459a1ae979bb0af019f   2.270797\n",
      "3   9b7d60f394284459a1ae979bb0af019f        NaN\n",
      "4   9b7d60f394284459a1ae979bb0af019f   2.466016\n",
      "5   9b7d60f394284459a1ae979bb0af019f   0.020335\n",
      "6   9b7d60f394284459a1ae979bb0af019f   1.064911\n",
      "7   9b7d60f394284459a1ae979bb0af019f   0.108305\n",
      "8   9b7d60f394284459a1ae979bb0af019f   1.364071\n",
      "9   9b7d60f394284459a1ae979bb0af019f   0.686090\n",
      "10  9b7d60f394284459a1ae979bb0af019f   2.985315\n",
      "11  9b7d60f394284459a1ae979bb0af019f   0.454322\n",
      "12  9b7d60f394284459a1ae979bb0af019f   0.371130\n",
      "13  9b7d60f394284459a1ae979bb0af019f   0.709315\n",
      "14  9b7d60f394284459a1ae979bb0af019f   2.333544\n",
      "15  9b7d60f394284459a1ae979bb0af019f   2.803816\n",
      "16  9b7d60f394284459a1ae979bb0af019f   2.337639\n",
      "17  9b7d60f394284459a1ae979bb0af019f   2.264304\n",
      "18  9b7d60f394284459a1ae979bb0af019f   1.470181\n",
      "19  9b7d60f394284459a1ae979bb0af019f   2.899851\n",
      "20  9b7d60f394284459a1ae979bb0af019f   1.566512\n",
      "21  9b7d60f394284459a1ae979bb0af019f   2.970164\n",
      "22  9b7d60f394284459a1ae979bb0af019f   2.014768\n",
      "23  9b7d60f394284459a1ae979bb0af019f   2.752715\n",
      "24  9b7d60f394284459a1ae979bb0af019f   0.826005 \n",
      "\n",
      "\n",
      "ULTRA\n",
      "[<curve.Curve object at 0x1554d3be7670>, <curve.Curve object at 0x1554d3bf7220>] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "data1 = dataset[[\"node/metrics_5\",'node/metrics_11']][:]\n",
    "print('HDF5')\n",
    "print(data1,'\\n\\n')\n",
    "\n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you will get a `pandas.DataFrame()`\n",
    "data2 = dataset[[\"creator\", \"myparam40\"]][:]\n",
    "print('CSV')\n",
    "print(data2,'\\n\\n')\n",
    "\n",
    "# ultra\n",
    "# returns a list with PyDV curve objects where data is in curve.x and curve.y see curve.__dict__ for more info\n",
    "data3 = dataset[['Gaussian (a: 5.0 w: 5.0 c: 0.0)', 'O + R']][:]\n",
    "print('ULTRA')\n",
    "print(data3,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e7fab-b414-469d-a08f-f2ec8f7997ce",
   "metadata": {},
   "source": [
    "#### Single Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4222431d-8592-4ff7-97a0-d2edcd5361ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5\n",
      "<HDF5 dataset \"metrics_5\": shape (2, 18), type \"<f4\"> \n",
      "\n",
      "\n",
      "CSV\n",
      "                             creator\n",
      "0   9b7d60f394284459a1ae979bb0af019f\n",
      "1   9b7d60f394284459a1ae979bb0af019f\n",
      "2   9b7d60f394284459a1ae979bb0af019f\n",
      "3   9b7d60f394284459a1ae979bb0af019f\n",
      "4   9b7d60f394284459a1ae979bb0af019f\n",
      "5   9b7d60f394284459a1ae979bb0af019f\n",
      "6   9b7d60f394284459a1ae979bb0af019f\n",
      "7   9b7d60f394284459a1ae979bb0af019f\n",
      "8   9b7d60f394284459a1ae979bb0af019f\n",
      "9   9b7d60f394284459a1ae979bb0af019f\n",
      "10  9b7d60f394284459a1ae979bb0af019f\n",
      "11  9b7d60f394284459a1ae979bb0af019f\n",
      "12  9b7d60f394284459a1ae979bb0af019f\n",
      "13  9b7d60f394284459a1ae979bb0af019f\n",
      "14  9b7d60f394284459a1ae979bb0af019f\n",
      "15  9b7d60f394284459a1ae979bb0af019f\n",
      "16  9b7d60f394284459a1ae979bb0af019f\n",
      "17  9b7d60f394284459a1ae979bb0af019f\n",
      "18  9b7d60f394284459a1ae979bb0af019f\n",
      "19  9b7d60f394284459a1ae979bb0af019f\n",
      "20  9b7d60f394284459a1ae979bb0af019f\n",
      "21  9b7d60f394284459a1ae979bb0af019f\n",
      "22  9b7d60f394284459a1ae979bb0af019f\n",
      "23  9b7d60f394284459a1ae979bb0af019f\n",
      "24  9b7d60f394284459a1ae979bb0af019f \n",
      "\n",
      "\n",
      "ULTRA\n",
      "[<curve.Curve object at 0x1554d3bf74f0>] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "data1 = dataset[\"node/metrics_5\"][:]\n",
    "print('HDF5')\n",
    "print(data1,'\\n\\n')\n",
    "\n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you will get a `pandas.DataFrame()`\n",
    "data2 = dataset[\"creator\"][:]\n",
    "print('CSV')\n",
    "print(data2,'\\n\\n')\n",
    "\n",
    "# ultra\n",
    "# returns a list with PyDV curve objects where data is in curve.x and curve.y see curve.__dict__ for more info\n",
    "data3 = dataset['Gaussian (a: 5.0 w: 5.0 c: 0.0)'][:]\n",
    "print('ULTRA')\n",
    "print(data3,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21866d-2860-4d29-a006-3f89eb723d1f",
   "metadata": {},
   "source": [
    "#### Describe Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda2116a-445b-43e7-81a5-d2916c1d1cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5\n",
      "{'size': (2, 18), 'format': 'hdf5', 'type': dtype('<f4'), 'dimensions': [{'name': 'cycles', 'first': np.int64(11), 'last': np.int64(8), 'length': 2}, {'name': 'elements', 'first': np.int64(17), 'last': np.int64(15), 'length': 18}]} \n",
      "\n",
      "\n",
      "CSV\n",
      "count                                   25\n",
      "unique                                   1\n",
      "top       9b7d60f394284459a1ae979bb0af019f\n",
      "freq                                    25\n",
      "Name: creator, dtype: object \n",
      "\n",
      "\n",
      "ULTRA\n",
      "{'name': 'Gaussian (a: 5.0 w: 5.0 c: 0.0)', 'size': 10, 'first_time': np.float64(-15.0), 'last_time': np.float64(12.272727272727257), 'min': np.float64(0.0006170490204333978), 'max': np.float64(4.995410739193376), 'type': dtype('float64')} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "print('HDF5')\n",
    "print(dataset.describe_feature(Id=associated_hdf5.id, feature=\"node/metrics_5\"),\"\\n\\n\")\n",
    "\n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you will get `pandas.DataFrame.describe()`\n",
    "print('CSV')\n",
    "print(dataset.describe_feature(Id=associated_csv_pandas.id, feature=\"creator\"),\"\\n\\n\")\n",
    "\n",
    "# ultra\n",
    "print('ULTRA')\n",
    "print(dataset.describe_feature(Id=associated_ultra.id, feature='Gaussian (a: 5.0 w: 5.0 c: 0.0)'),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6511fa-faee-4271-9ca5-996850b797f4",
   "metadata": {},
   "source": [
    "## Outer Loop\n",
    "\n",
    "This outer loop groups the individual simulations into ensembles for organization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51e2c8-9e79-412a-bee5-654efa53f947",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adding Dataset to Ensembles\n",
    "\n",
    "Once there are a lot of simulations that have been completed and their datasets created, we can group them together.\n",
    "\n",
    "See [Example_Ensembles.ipynb](Example_Ensembles.ipynb) for more information on ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518f9057-2abf-4bcf-af28-beaa8a045a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Ensemble -----\n",
      "KOSH ENSEMBLE\n",
      "\tid: ae36aa8f8e49479c93bef45d440f8347\n",
      "\tname: My Example Ensemble\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: My Example Ensemble\n",
      "\tproject: Example\n",
      "\troot: /root/path/for/ensemble\n",
      "--- Associated Data (0)---\n",
      "--- Member Datasets (1)---\n",
      "\t['obj1'] \n",
      "\n",
      "\n",
      "----- Dataset -----\n",
      "KOSH DATASET\n",
      "\tid: obj1\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 3.3\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "\tsome_variable_mean: 4.7749999999999995\n",
      "--- Associated Data (5)---\n",
      "\tMime_type: hdf5\n",
      "\t\t../tests/baselines/node_extracts2/node_extracts2.hdf5 ( b8a7bd3c354f4af0b2b612b87895a389 )\n",
      "\tMime_type: image/png\n",
      "\t\tfoo.png ( obj1 )\n",
      "\tMime_type: pandas/csv\n",
      "\t\t../tests/baselines/csv/my_csv_file.csv ( 6a2390092c3f42fb96a869c67baa1fdc )\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( timeplot_1, my_curves, my_other_curves )\n",
      "\tMime_type: ultra\n",
      "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult ( 5aa6593ccfa749b29c50be6feb91be8f )\n",
      "--- Ensembles (1)---\n",
      "\t['ae36aa8f8e49479c93bef45d440f8347']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ae36aa8f8e49479c93bef45d440f8347 ---\n",
      "\t\t['project', 'root']\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "# Try to see if it already exists\n",
    "ensemble = list(store.find_ensembles(name=\"My Example Ensemble\"))\n",
    "\n",
    "if len(ensemble)==0: # create ensemble if doesn't exist\n",
    "    ensemble = store.create_ensemble(name=\"My Example Ensemble\",\n",
    "                                    metadata={\"root\":\"/root/path/for/ensemble\",\n",
    "                                            \"project\":\"Example\"})\n",
    "else: # already exists\n",
    "    ensemble = ensemble[0] # get first ensemble out of find results\n",
    "\n",
    "# add this dataset to this ensemble\n",
    "ensemble.add(dataset)\n",
    "\n",
    "print('----- Ensemble -----')\n",
    "print(ensemble,\"\\n\\n\") # This will display the ids' of the datasets in the ensemble\n",
    "\n",
    "print('----- Dataset -----')\n",
    "print(dataset) # This will now display the ensembles this dataset is a member off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06eeb6-9f6d-4233-b708-cf80aa55476f",
   "metadata": {},
   "source": [
    "### Adding Multiple Datasets to Ensembles with the same attributes and organizing with ensemble tags\n",
    "\n",
    "Datasets also can be part of multiple ensembles and they can be further organized within a single ensemble using `ensemble_tags`. \n",
    "\n",
    "For example, say you want to add your train, validation, and test datasets to a single ensemble but need to organize them as such. Adding an attribute to the dataset would make that attribute the same across all ensembles but the train, validation, and test split is randomized for each ensemble. Adding an attribute to the ensemble would be at the ensemble level and thus you would need three ensembles one for train, validation, and test. `ensemble_tags` allow the user to organize the datasets within the ensemble.\n",
    "\n",
    "We also use `inherit_attributes=False` so that the datasets and ensembles as well as the different ensemebles containing the same datasets can have the same attributes or else there will be a clash since the same attributes are seen.\n",
    "\n",
    "**Note:** If a dataset was added to another ensemble using the default parameter `inherit_attributes=True` and the new ensemble and/or dataset attributes have the same name, there will be a conflict. In order to fix this you need to update the special ensemble tag `'INHERIT_ATTRIBUTES'` to `False` for that other dataset ensemble relation. This means that the dataset attributes will no longer be tied to that other ensemble so there will no longer be a conflict. If the dataset belongs to multiple ensembles with `inherit_attributes=True` (and there are attribute conflicts), this will need to be done for all those different ensembles: `dataset.add_ensemble_tags(ensemble_id, {'INHERIT_ATTRIBUTES': False})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b84e4a8-e401-462d-851c-c76818fc44b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH ENSEMBLE\n",
      "\tid: ens_9\n",
      "\tname: Unnamed Ensemble\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Ensemble\n",
      "\tproject: Example 9\n",
      "\troot: /root/path/for/ensemble9/\n",
      "--- Associated Data (0)---\n",
      "--- Member Datasets (20)---\n",
      "\t['ds_0', 'ds_1', 'ds_2', 'ds_3', 'ds_4', 'ds_5', 'ds_6', 'ds_7', 'ds_8', 'ds_9', 'ds_10', 'ds_11', 'ds_12', 'ds_13', 'ds_14', 'ds_15', 'ds_16', 'ds_17', 'ds_18', 'ds_19']\n",
      "KOSH DATASET\n",
      "\tid: ds_19\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 0\n",
      "\tparam2: 2\n",
      "\tparam3: -82\n",
      "\tparam4: 849\n",
      "\tparam5: 2000\n",
      "\tparam6: -48008\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "temp_datasets = []\n",
    "for i in range(20):\n",
    "    metadata = {\"param1\": random.randint(0, 1),\n",
    "                \"param2\": random.randint(-10, 10),\n",
    "                \"param3\": random.randint(-100, 100),\n",
    "                \"param4\": random.randint(-1000, 1000),\n",
    "                \"param5\": random.randint(-10000, 10000),\n",
    "                \"param6\": random.randint(-100000, 100000),\n",
    "                }\n",
    "\n",
    "    temp_dataset = store.create(id=f\"ds_{i}\", metadata=metadata)\n",
    "    temp_datasets.append(temp_dataset)\n",
    "\n",
    "for i in range(10):\n",
    "    ensemble = store.create_ensemble(id=f\"ens_{i}\",\n",
    "                                    metadata={\"root\":f\"/root/path/for/ensemble{i}/\",\n",
    "                                              \"project\":f\"Example {i}\"})\n",
    "    for j, temp_ds in enumerate(temp_datasets):\n",
    "\n",
    "        ensemble_tags = {}\n",
    "\n",
    "        if j % 2 == 0:\n",
    "            ensemble_tags[\"even_or_odd\"] = \"even\"\n",
    "        else:\n",
    "            ensemble_tags[\"even_or_odd\"] = \"odd\"\n",
    "\n",
    "        if j <= 11:\n",
    "            ensemble_tags[\"data_type\"] = \"train data\"\n",
    "        elif j <= 15:\n",
    "            ensemble_tags[\"data_type\"] = \"validation data\"\n",
    "        else:\n",
    "            ensemble_tags[\"data_type\"] = \"test data\"\n",
    "\n",
    "        ensemble.add(temp_ds, inherit_attributes=False, ensemble_tags=ensemble_tags)\n",
    "\n",
    "print(ensemble)\n",
    "print(temp_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146719e-b55c-4edd-8d59-1b31217b4036",
   "metadata": {},
   "source": [
    "### Finding Datasets within Ensembles\n",
    "We can use `ensemble.find()` to narrow down the search to datasets only within the ensemble instead of searching the whole store with `store.find()`. We can filter by attributes like `store.find()` but we have the added benefit of filtering by `ensemble_tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c7e514-c429-4983-af3a-36614e61d0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/moreno45/Projects/ASCAML/kosh/kosh/store.py:1026: UserWarning: It is not recommended to use the find function by mixing keys and the reserved key `data`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: ds_7\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: -1\n",
      "\tparam3: 58\n",
      "\tparam4: -613\n",
      "\tparam5: 7372\n",
      "\tparam6: -91469\n",
      "\ttest_attr: 42\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: ds_0\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 71\n",
      "\tparam4: 653\n",
      "\tparam5: 2490\n",
      "\tparam6: 26965\n",
      "\ttest_attr: 42\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: ds_2\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: -9\n",
      "\tparam3: 11\n",
      "\tparam4: -600\n",
      "\tparam5: 4862\n",
      "\tparam6: 99824\n",
      "\ttest_attr: 42\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "target_data = {'param1': 1,\n",
    "               'param3': DataRange(min=0, max=100, max_inclusive=True)}\n",
    "target_ensemble_tags = {\"data_type\": \"train data\"}\n",
    "found_datasets =  list(ensemble.find_datasets(data=target_data, ensemble_tags=target_ensemble_tags))\n",
    "for fd in found_datasets:\n",
    "    setattr(fd, 'test_attr', 42) # setting new attribute for each of the found datasets\n",
    "    print(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f1ea4-e4eb-459b-a83a-e6b96f1ddc8c",
   "metadata": {},
   "source": [
    "### Finding Datasets within whole Store\n",
    "\n",
    "You can also filter datasets at the overall store level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64519e48-8696-456d-bd56-7d9738521d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: ds_17\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: 1\n",
      "\tparam3: 87\n",
      "\tparam4: 824\n",
      "\tparam5: 5570\n",
      "\tparam6: 94725\n",
      "\ttotal: 10\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: ds_0\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 71\n",
      "\tparam4: 653\n",
      "\tparam5: 2490\n",
      "\tparam6: 26965\n",
      "\ttest_attr: 42\n",
      "\ttotal: 10\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: ds_16\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: 3\n",
      "\tparam3: 68\n",
      "\tparam4: -173\n",
      "\tparam5: 2213\n",
      "\tparam6: 35634\n",
      "\ttotal: 10\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: obj1\n",
      "\tname: ???\n",
      "\tcreator: ???\n",
      "\n",
      "--- Attributes ---\n",
      "\tparam1: 1\n",
      "\tparam2: 2\n",
      "\tparam3: 3.3\n",
      "\tparam4: 1\n",
      "\tparam5: test\n",
      "\tparam6: 3.14\n",
      "\tsome_variable_mean: 4.7749999999999995\n",
      "\ttotal: 10\n",
      "--- Associated Data (5)---\n",
      "\tMime_type: hdf5\n",
      "\t\t../tests/baselines/node_extracts2/node_extracts2.hdf5 ( b8a7bd3c354f4af0b2b612b87895a389 )\n",
      "\tMime_type: image/png\n",
      "\t\tfoo.png ( obj1 )\n",
      "\tMime_type: pandas/csv\n",
      "\t\t../tests/baselines/csv/my_csv_file.csv ( 6a2390092c3f42fb96a869c67baa1fdc )\n",
      "\tMime_type: sina/curve\n",
      "\t\tinternal ( timeplot_1, my_curves, my_other_curves )\n",
      "\tMime_type: ultra\n",
      "\t\t/g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult ( 5aa6593ccfa749b29c50be6feb91be8f )\n",
      "--- Ensembles (1)---\n",
      "\t['ae36aa8f8e49479c93bef45d440f8347']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ae36aa8f8e49479c93bef45d440f8347 ---\n",
      "\t\t['project', 'root']\n",
      "--- Alias Feature Dictionary ---\n",
      "KOSH DATASET\n",
      "\tid: ds_2\n",
      "\tname: Unnamed Dataset\n",
      "\tcreator: moreno45\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: moreno45\n",
      "\tname: Unnamed Dataset\n",
      "\tparam1: 1\n",
      "\tparam2: -9\n",
      "\tparam3: 11\n",
      "\tparam4: -600\n",
      "\tparam5: 4862\n",
      "\tparam6: 99824\n",
      "\ttest_attr: 42\n",
      "\ttotal: 10\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (10)---\n",
      "\t['ens_0', 'ens_1', 'ens_2', 'ens_3', 'ens_4', 'ens_5', 'ens_6', 'ens_7', 'ens_8', 'ens_9']\n",
      "--- Ensemble Attributes ---\n",
      "\t--- Ensemble ens_0 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_1 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_2 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_3 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_4 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_5 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_6 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_7 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_8 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "\t--- Ensemble ens_9 ---\n",
      "\t\t['project', 'root']\n",
      "\t\t--- Ensemble Tags ---\n",
      "\t\t\t['data_type', 'even_or_odd']\n",
      "--- Alias Feature Dictionary ---\n"
     ]
    }
   ],
   "source": [
    "target_data = {'param1': 1,\n",
    "               'param3': DataRange(min=0, max=100, max_inclusive=True),\n",
    "               'param6': DataRange(min=-1000, max=100000)}\n",
    "\n",
    "found_datasets = list(store.find(data=target_data)) #list(store.find()) for all datasets\n",
    "\n",
    "for fd in found_datasets:\n",
    "    setattr(fd, 'total', 10) # setting new attribute for each of the found datasets\n",
    "    print(fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ead79-469c-4521-a3b5-5e11b72b228b",
   "metadata": {},
   "source": [
    "### Converting `store.find()` method to Pandas DataFrame\n",
    "\n",
    "You can also pass in the same arguments in the `store.find()` method to the  `store.to_dataframe()` method to get the attributes of the filtered datasets. By default, it will always include ['id', 'name', 'creator']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58efb7e0-39c4-47ed-9b0c-60c267d558af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Datasets\n",
      "                                    id             name  \\\n",
      "0                                ds_18  Unnamed Dataset   \n",
      "1     6c35fb8c25034483af7031fada507062             16.0   \n",
      "2     f03bfb80e755442bb59e46da9038aa3b             18.0   \n",
      "3     c0215e9c4080430da59979f71009c045             14.0   \n",
      "4     b1e66c735ac6483d88fe041ab70dab2c              0.0   \n",
      "..                                 ...              ...   \n",
      "57                                ds_8  Unnamed Dataset   \n",
      "58    23cecefa740346d8970bca303ce0f38b             19.0   \n",
      "59  281bdb406b99412880af991e9dd77047_3             <NA>   \n",
      "60  57e8a2e6df3e44a68d675977e91712ba_6             <NA>   \n",
      "61                                ds_0  Unnamed Dataset   \n",
      "\n",
      "                             creator  data_type  my_other_att  passed  tempF  \\\n",
      "0   9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "1   9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "2   9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "3   9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "4   9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "..                               ...        ...           ...     ...    ...   \n",
      "57  9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "58  9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "59                              <NA>      train          77.0   False  -34.0   \n",
      "60                              <NA>       <NA>          <NA>    <NA>   <NA>   \n",
      "61  9b7d60f394284459a1ae979bb0af019f       <NA>          <NA>    <NA>   <NA>   \n",
      "\n",
      "        D Unnamed: 0 att_1  ... param4 param5  param6 project  root  \\\n",
      "0    <NA>       <NA>  <NA>  ...     17   7129  -17326    <NA>  <NA>   \n",
      "1    <NA>        4.0  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "2    <NA>       23.0  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "3    <NA>        8.0  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "4    <NA>        9.0  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "..    ...        ...   ...  ...    ...    ...     ...     ...   ...   \n",
      "57   <NA>       <NA>  <NA>  ...    610   4821   20859    <NA>  <NA>   \n",
      "58   <NA>       18.0  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "59   <NA>       <NA>   1.0  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "60  local       <NA>  <NA>  ...   <NA>   <NA>    <NA>    <NA>  <NA>   \n",
      "61   <NA>       <NA>  <NA>  ...    653   2490   26965    <NA>  <NA>   \n",
      "\n",
      "   some_variable_mean start_time test_attr total total_energy  \n",
      "0                <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "1                <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "2                <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "3                <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "4                <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "..                ...        ...       ...   ...          ...  \n",
      "57               <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "58               <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "59               <NA>       <NA>      <NA>  <NA>         <NA>  \n",
      "60               <NA>   0.876553      <NA>  <NA>         77.6  \n",
      "61               <NA>       <NA>        42    10         <NA>  \n",
      "\n",
      "[62 rows x 33 columns] \n",
      "\n",
      "\n",
      "Filtered Datasets\n",
      "      id             name                           creator  param1  param2  \\\n",
      "0  ds_17  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       1   \n",
      "1   ds_0  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       2   \n",
      "2  ds_16  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       3   \n",
      "3   obj1             <NA>                              <NA>       1       2   \n",
      "4   ds_2  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -9   \n",
      "\n",
      "   param3  param4 param5    param6  project                     root  \\\n",
      "0    87.0     824   5570  94725.00     <NA>                     <NA>   \n",
      "1    71.0     653   2490  26965.00     <NA>                     <NA>   \n",
      "2    68.0    -173   2213  35634.00     <NA>                     <NA>   \n",
      "3     3.3       1   test      3.14  Example  /root/path/for/ensemble   \n",
      "4    11.0    -600   4862  99824.00     <NA>                     <NA>   \n",
      "\n",
      "  some_variable_mean test_attr  total  \n",
      "0               <NA>      <NA>     10  \n",
      "1               <NA>        42     10  \n",
      "2               <NA>      <NA>     10  \n",
      "3              4.775      <NA>     10  \n",
      "4               <NA>        42     10   \n",
      "\n",
      "\n",
      "Filtered Datasets with specific columns\n",
      "      id             name                           creator  param1    param6\n",
      "0  ds_17  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1  94725.00\n",
      "1   ds_0  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1  26965.00\n",
      "2  ds_16  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1  35634.00\n",
      "3   obj1             <NA>                              <NA>       1      3.14\n",
      "4   ds_2  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1  99824.00 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All datasets\n",
    "df = store.to_dataframe()\n",
    "print('All Datasets')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Filtered datasets\n",
    "df = store.to_dataframe(data=target_data)\n",
    "print('Filtered Datasets')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Specific columns\n",
    "df = store.to_dataframe(data=target_data, data_columns=['param1', 'param6'])\n",
    "print('Filtered Datasets with specific columns')\n",
    "print(df,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c60728-6fd1-42d4-917a-df9ca1109e6e",
   "metadata": {},
   "source": [
    "### Converting `dataset.find()` method to Pandas DataFrame\n",
    "\n",
    "You can also pass in the same arguments in the `dataset.find()` method to the  `dataset.to_dataframe()` method to get the attributes of the filtered associated files. By default, it will always include ['id', 'mime_type', 'uri', 'associated']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d10bef1-1f00-4f00-8575-6262d253a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Associated Files\n",
      "                                 id   mime_type  \\\n",
      "0  6a2390092c3f42fb96a869c67baa1fdc  pandas/csv   \n",
      "1  b8a7bd3c354f4af0b2b612b87895a389        hdf5   \n",
      "2  5aa6593ccfa749b29c50be6feb91be8f       ultra   \n",
      "3                              obj1        <NA>   \n",
      "\n",
      "                                                 uri associated  \\\n",
      "0             ../tests/baselines/csv/my_csv_file.csv     [obj1]   \n",
      "1  ../tests/baselines/node_extracts2/node_extract...     [obj1]   \n",
      "2  /g/g20/moreno45/Projects/ASCAML/kosh/examples/...     [obj1]   \n",
      "3                                               <NA>       <NA>   \n",
      "\n",
      "                                            fast_sha  \\\n",
      "0  6ae16fcd8a5bfc197d94451a64e3aa76b3cdce1f2af548...   \n",
      "1  2c0f45d3ab840e47510a3fc1e463884de3765191cb3d07...   \n",
      "2  448a457f7344ece8c8be9b4ff383ab8258cb3401bc391e...   \n",
      "3                                               <NA>   \n",
      "\n",
      "                    loader_kwargs my other param my param param1   param10  \\\n",
      "0  \u0004\u0012\u0000\u0000\u0000\u0000\u0000\u0000\u0000}\\tindex_colK\u0000s.           <NA>       10   <NA>      <NA>   \n",
      "1                            <NA>   Example Text     <NA>   <NA>  my value   \n",
      "2                            <NA>           <NA>      560   <NA>      <NA>   \n",
      "3                            <NA>           <NA>     <NA>      1      <NA>   \n",
      "\n",
      "   ...         param20 param3 param30 param4 param5 param6  project  \\\n",
      "0  ...  my other value   <NA>    <NA>   <NA>   <NA>   <NA>     <NA>   \n",
      "1  ...            <NA>   <NA>    <NA>   <NA>   <NA>   <NA>     <NA>   \n",
      "2  ...            <NA>   <NA>      45   <NA>   <NA>   <NA>     <NA>   \n",
      "3  ...            <NA>    3.3    <NA>      1   test   3.14  Example   \n",
      "\n",
      "                      root some_variable_mean total  \n",
      "0                     <NA>               <NA>  <NA>  \n",
      "1                     <NA>               <NA>  <NA>  \n",
      "2                     <NA>               <NA>  <NA>  \n",
      "3  /root/path/for/ensemble              4.775    10  \n",
      "\n",
      "[4 rows x 21 columns] \n",
      "\n",
      "\n",
      "Filtered Associated Files\n",
      "                                 id   mime_type  \\\n",
      "0  6a2390092c3f42fb96a869c67baa1fdc  pandas/csv   \n",
      "\n",
      "                                      uri associated  \\\n",
      "0  ../tests/baselines/csv/my_csv_file.csv     [obj1]   \n",
      "\n",
      "                                            fast_sha  \\\n",
      "0  6ae16fcd8a5bfc197d94451a64e3aa76b3cdce1f2af548...   \n",
      "\n",
      "                    loader_kwargs  my param         param20  \n",
      "0  \u0004\u0012\u0000\u0000\u0000\u0000\u0000\u0000\u0000}\\tindex_colK\u0000s.        10  my other value   \n",
      "\n",
      "\n",
      "Filtered Associated Files with specific columns\n",
      "                                 id   mime_type  \\\n",
      "0  6a2390092c3f42fb96a869c67baa1fdc  pandas/csv   \n",
      "\n",
      "                                      uri associated         param20  \n",
      "0  ../tests/baselines/csv/my_csv_file.csv     [obj1]  my other value   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All Associated Files\n",
    "df = dataset.to_dataframe()\n",
    "print('All Associated Files')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Filtered Associated Files\n",
    "target_data = {'my param': 10}\n",
    "df = dataset.to_dataframe(data=target_data)\n",
    "print('Filtered Associated Files')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Specific columns\n",
    "df = dataset.to_dataframe(data=target_data, data_columns=['param20'])\n",
    "print('Filtered Associated Files with specific columns')\n",
    "print(df,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce4c2f-3779-4913-b2fd-8831b0d9b1b1",
   "metadata": {},
   "source": [
    "### Converting `ensemble.find()` method to Pandas DataFrame\n",
    "\n",
    "You can also pass in the same arguments in the `ensemble.find()` method to the  `ensemble.to_dataframe()` method to get the attributes of the filtered datasets within that specific ensemble. By default, it will always include ['id', 'name', 'creator'] and both the ensemble attributes and ensemble tags but they can be turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5c0fa51-034f-498f-a6af-15785d1f7db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Datasets in Ensemble\n",
      "       id             name                           creator  param1  param2  \\\n",
      "0   ds_18  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -5   \n",
      "1    ds_4  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -9   \n",
      "2   ds_17  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       1   \n",
      "3    ds_5  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       0   \n",
      "4   ds_12  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0      -6   \n",
      "5   ds_10  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -1   \n",
      "6   ds_19  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0       2   \n",
      "7   ds_11  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0      -8   \n",
      "8   ds_16  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       3   \n",
      "9    ds_0  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       2   \n",
      "10   ds_9  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0      -6   \n",
      "11  ds_13  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       5   \n",
      "12   ds_2  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -9   \n",
      "13   ds_1  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0       6   \n",
      "14  ds_14  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0       4   \n",
      "15   ds_3  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0       8   \n",
      "16   ds_8  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0       8   \n",
      "17  ds_15  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       0     -10   \n",
      "18   ds_7  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -1   \n",
      "19   ds_6  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -5   \n",
      "\n",
      "    param3  param4  param5  param6 test_attr total  \\\n",
      "0       81      17    7129  -17326      <NA>  <NA>   \n",
      "1      -60    -711   -3951  -24929      <NA>  <NA>   \n",
      "2       87     824    5570   94725      <NA>    10   \n",
      "3      -10    -157    9029   38471      <NA>  <NA>   \n",
      "4       -5    -998   -1017   35821      <NA>  <NA>   \n",
      "5      -42    -981   -6512   22597      <NA>  <NA>   \n",
      "6      -82     849    2000  -48008      <NA>  <NA>   \n",
      "7      -86     898    1446   72877      <NA>  <NA>   \n",
      "8       68    -173    2213   35634      <NA>    10   \n",
      "9       71     653    2490   26965        42    10   \n",
      "10      92     -24    2844   -1197      <NA>  <NA>   \n",
      "11      15    -246    3575  -62320      <NA>  <NA>   \n",
      "12      11    -600    4862   99824        42    10   \n",
      "13     -47    -622    6768  -71619      <NA>  <NA>   \n",
      "14      39    -245   -2950  -89900      <NA>  <NA>   \n",
      "15     -31    -610    6091   52039      <NA>  <NA>   \n",
      "16      25     610    4821   20859      <NA>  <NA>   \n",
      "17     -13     998   -3249    8913      <NA>  <NA>   \n",
      "18      58    -613    7372  -91469        42  <NA>   \n",
      "19     -58     534    1411   64253      <NA>  <NA>   \n",
      "\n",
      "   ens_9_ENSEMBLE_ATTRIBUTE_id ens_9_ENSEMBLE_ATTRIBUTE_name  \\\n",
      "0                        ens_9              Unnamed Ensemble   \n",
      "1                        ens_9              Unnamed Ensemble   \n",
      "2                        ens_9              Unnamed Ensemble   \n",
      "3                        ens_9              Unnamed Ensemble   \n",
      "4                        ens_9              Unnamed Ensemble   \n",
      "5                        ens_9              Unnamed Ensemble   \n",
      "6                        ens_9              Unnamed Ensemble   \n",
      "7                        ens_9              Unnamed Ensemble   \n",
      "8                        ens_9              Unnamed Ensemble   \n",
      "9                        ens_9              Unnamed Ensemble   \n",
      "10                       ens_9              Unnamed Ensemble   \n",
      "11                       ens_9              Unnamed Ensemble   \n",
      "12                       ens_9              Unnamed Ensemble   \n",
      "13                       ens_9              Unnamed Ensemble   \n",
      "14                       ens_9              Unnamed Ensemble   \n",
      "15                       ens_9              Unnamed Ensemble   \n",
      "16                       ens_9              Unnamed Ensemble   \n",
      "17                       ens_9              Unnamed Ensemble   \n",
      "18                       ens_9              Unnamed Ensemble   \n",
      "19                       ens_9              Unnamed Ensemble   \n",
      "\n",
      "   ens_9_ENSEMBLE_ATTRIBUTE_creator ens_9_ENSEMBLE_ATTRIBUTE_project  \\\n",
      "0                          moreno45                        Example 9   \n",
      "1                          moreno45                        Example 9   \n",
      "2                          moreno45                        Example 9   \n",
      "3                          moreno45                        Example 9   \n",
      "4                          moreno45                        Example 9   \n",
      "5                          moreno45                        Example 9   \n",
      "6                          moreno45                        Example 9   \n",
      "7                          moreno45                        Example 9   \n",
      "8                          moreno45                        Example 9   \n",
      "9                          moreno45                        Example 9   \n",
      "10                         moreno45                        Example 9   \n",
      "11                         moreno45                        Example 9   \n",
      "12                         moreno45                        Example 9   \n",
      "13                         moreno45                        Example 9   \n",
      "14                         moreno45                        Example 9   \n",
      "15                         moreno45                        Example 9   \n",
      "16                         moreno45                        Example 9   \n",
      "17                         moreno45                        Example 9   \n",
      "18                         moreno45                        Example 9   \n",
      "19                         moreno45                        Example 9   \n",
      "\n",
      "   ens_9_ENSEMBLE_ATTRIBUTE_root ens_9_ENSEMBLE_TAG_data_type  \\\n",
      "0      /root/path/for/ensemble9/                    test data   \n",
      "1      /root/path/for/ensemble9/                   train data   \n",
      "2      /root/path/for/ensemble9/                    test data   \n",
      "3      /root/path/for/ensemble9/                   train data   \n",
      "4      /root/path/for/ensemble9/              validation data   \n",
      "5      /root/path/for/ensemble9/                   train data   \n",
      "6      /root/path/for/ensemble9/                    test data   \n",
      "7      /root/path/for/ensemble9/                   train data   \n",
      "8      /root/path/for/ensemble9/                    test data   \n",
      "9      /root/path/for/ensemble9/                   train data   \n",
      "10     /root/path/for/ensemble9/                   train data   \n",
      "11     /root/path/for/ensemble9/              validation data   \n",
      "12     /root/path/for/ensemble9/                   train data   \n",
      "13     /root/path/for/ensemble9/                   train data   \n",
      "14     /root/path/for/ensemble9/              validation data   \n",
      "15     /root/path/for/ensemble9/                   train data   \n",
      "16     /root/path/for/ensemble9/                   train data   \n",
      "17     /root/path/for/ensemble9/              validation data   \n",
      "18     /root/path/for/ensemble9/                   train data   \n",
      "19     /root/path/for/ensemble9/                   train data   \n",
      "\n",
      "   ens_9_ENSEMBLE_TAG_even_or_odd  \n",
      "0                            even  \n",
      "1                            even  \n",
      "2                             odd  \n",
      "3                             odd  \n",
      "4                            even  \n",
      "5                            even  \n",
      "6                             odd  \n",
      "7                             odd  \n",
      "8                            even  \n",
      "9                            even  \n",
      "10                            odd  \n",
      "11                            odd  \n",
      "12                           even  \n",
      "13                            odd  \n",
      "14                           even  \n",
      "15                            odd  \n",
      "16                           even  \n",
      "17                            odd  \n",
      "18                            odd  \n",
      "19                           even   \n",
      "\n",
      "\n",
      "Filtered Datasets in Ensemble\n",
      "     id             name                           creator  param1  param2  \\\n",
      "0  ds_7  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -1   \n",
      "1  ds_0  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1       2   \n",
      "2  ds_2  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f       1      -9   \n",
      "\n",
      "   param3  param4  param5  param6  test_attr total  \\\n",
      "0      58    -613    7372  -91469         42  <NA>   \n",
      "1      71     653    2490   26965         42    10   \n",
      "2      11    -600    4862   99824         42    10   \n",
      "\n",
      "  ens_9_ENSEMBLE_ATTRIBUTE_id ens_9_ENSEMBLE_ATTRIBUTE_name  \\\n",
      "0                       ens_9              Unnamed Ensemble   \n",
      "1                       ens_9              Unnamed Ensemble   \n",
      "2                       ens_9              Unnamed Ensemble   \n",
      "\n",
      "  ens_9_ENSEMBLE_ATTRIBUTE_creator ens_9_ENSEMBLE_ATTRIBUTE_project  \\\n",
      "0                         moreno45                        Example 9   \n",
      "1                         moreno45                        Example 9   \n",
      "2                         moreno45                        Example 9   \n",
      "\n",
      "  ens_9_ENSEMBLE_ATTRIBUTE_root ens_9_ENSEMBLE_TAG_data_type  \\\n",
      "0     /root/path/for/ensemble9/                   train data   \n",
      "1     /root/path/for/ensemble9/                   train data   \n",
      "2     /root/path/for/ensemble9/                   train data   \n",
      "\n",
      "  ens_9_ENSEMBLE_TAG_even_or_odd  \n",
      "0                            odd  \n",
      "1                           even  \n",
      "2                           even   \n",
      "\n",
      "\n",
      "Filtered Associated Files with specific columns\n",
      "     id             name                           creator param20\n",
      "0  ds_7  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f    <NA>\n",
      "1  ds_0  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f    <NA>\n",
      "2  ds_2  Unnamed Dataset  9b7d60f394284459a1ae979bb0af019f    <NA> \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/moreno45/Projects/ASCAML/kosh/kosh/store.py:1026: UserWarning: It is not recommended to use the find function by mixing keys and the reserved key `data`\n",
      "  warnings.warn(\n",
      "/g/g20/moreno45/Projects/ASCAML/kosh/kosh/store.py:1026: UserWarning: It is not recommended to use the find function by mixing keys and the reserved key `data`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# All Datasets in Ensemble\n",
    "df = ensemble.to_dataframe()\n",
    "print('All Datasets in Ensemble')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Filtered Datasets in Ensemble\n",
    "target_data = {'param1': 1,\n",
    "               'param3': DataRange(min=0, max=100, max_inclusive=True)}\n",
    "target_ensemble_tags = {\"data_type\": \"train data\"}\n",
    "df = ensemble.to_dataframe(data=target_data, ensemble_tags=target_ensemble_tags)\n",
    "print('Filtered Datasets in Ensemble')\n",
    "print(df,'\\n\\n')\n",
    "\n",
    "# Specific columns without ensemble attributes or ensemble tags\n",
    "df = ensemble.to_dataframe(data=target_data, ensemble_tags=target_ensemble_tags,\n",
    "                           data_columns=['param20'],\n",
    "                           include_ensemble_attributes=False, include_ensemble_tags=False)\n",
    "print('Filtered Associated Files with specific columns')\n",
    "print(df,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d971bd-fa8b-4e6b-8685-5c79a57541dd",
   "metadata": {},
   "source": [
    "### Other Capabilities\n",
    "\n",
    "#### Moving Datasets\n",
    "If you want to move datasets around see [Example_07_Transferring_Datasets.ipynb](Example_07_Transferring_Datasets.ipynb) and [Example_Moving_Datasets.ipynb](Example_Moving_Datasets.ipynb).\n",
    "\n",
    "#### Parallel Access to Kosh Store\n",
    "If you are running a lot of simulations in parallel (e.g. through Maestro or Merlin) and need to access the Kosh store in parallel as well see [Example_ThreadSafe.ipynb](Example_ThreadSafe.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952562d8-0eb5-4f54-b785-30cf9cb7087c",
   "metadata": {},
   "source": [
    "## Using PyDV for Further Analysis\n",
    "\n",
    "You can convert the features of a dataset into PyDV curves **even if they are NOT ultra files** by providing their x and y data to `pydvpy.makecurve()`. Then you can use PyDV for further analysis. \n",
    "\n",
    "See PyDV API Specification documentation:\n",
    "* https://lc.llnl.gov/weave/pydv/html/pydv.html\n",
    "* https://pydv.readthedocs.io/en/latest/pydv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd883fd-ead3-41b7-b393-5a4396965c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "HDF5\n",
      "<HDF5 dataset \"metrics_5\": shape (2, 18), type \"<f4\"> \n",
      "\n",
      "\n",
      "CSV\n",
      "    myparam10  myparam40\n",
      "0         NaN        NaN\n",
      "1    1.279276   0.950918\n",
      "2    1.743174   2.270797\n",
      "3         NaN        NaN\n",
      "4    0.144626   2.466016\n",
      "5    1.382974   0.020335\n",
      "6    0.051635   1.064911\n",
      "7    1.391787   0.108305\n",
      "8    0.289573   1.364071\n",
      "9    0.294249   0.686090\n",
      "10   1.079470   2.985315\n",
      "11   1.914257   0.454322\n",
      "12   0.396960   0.371130\n",
      "13   1.513962   0.709315\n",
      "14   0.295615   2.333544\n",
      "15   1.340525   2.803816\n",
      "16   0.026997   2.337639\n",
      "17   1.795573   2.264304\n",
      "18   0.664151   1.470181\n",
      "19   1.176025   2.899851\n",
      "20   1.501699   1.566512\n",
      "21   1.366581   2.970164\n",
      "22   1.579366   2.014768\n",
      "23   0.819499   2.752715\n",
      "24   0.204605   0.826005 \n",
      "\n",
      "\n",
      "[<curve.Curve object at 0x1554d3be4820>, <curve.Curve object at 0x1554d3be4e20>, <curve.Curve object at 0x1554d3be4970>, <curve.Curve object at 0x1554d3be4370>, <curve.Curve object at 0x1554d3be4d60>, <curve.Curve object at 0x1554d3be4fa0>, <curve.Curve object at 0x1554d3be4dc0>, <curve.Curve object at 0x1554d3be4d90>, <curve.Curve object at 0x1554d3be71c0>, <curve.Curve object at 0x1554d3be4e50>, <curve.Curve object at 0x1554d3be4df0>, <curve.Curve object at 0x1554d3be7310>, <curve.Curve object at 0x1554d3be7040>, <curve.Curve object at 0x1554d3be4e80>, <curve.Curve object at 0x1554d3be7520>, <curve.Curve object at 0x1554d3be4fd0>, <curve.Curve object at 0x1554d3be7130>, <curve.Curve object at 0x1554d3be72e0>, <curve.Curve object at 0x1554d3be75b0>, <curve.Curve object at 0x1554d3be7370>, <curve.Curve object at 0x1554d3a8bd60>, <curve.Curve object at 0x1554d3c225e0>]\n",
      "Gaussian (a: 5.0 w: 5.0 c: 0.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Gaussian (a: 5.0 w: 5.0 c: 50.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "A + B\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Straight Line (m: 0.125 b: -2.5 xmin: 60.0 xmax: 40.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "a.y+numpy.random.normal(size=100)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "E + B\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Gaussian (a: 10.0 w: 5.0 c: 70.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "g.y+numpy.random.normal(size=500)+70\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "F + H\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Gaussian (a: 20.0 w: 5.0 c: 20.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "j.y+numpy.random.normal(size=50)+20\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "I + K\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Gaussian (a: 20.0 w: 1.0 c: 50.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "m.y+numpy.random.normal(size=500)+50\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "L + N\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "Gaussian (a: 50.0 w: 0.25 c: 10.0)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "p.x+numpy.random.normal(size=200)\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "P + Q\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "O + R\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "A + D\n",
      "\t /g/g20/moreno45/Projects/ASCAML/kosh/examples/my_ult_file.ult\n",
      "\n",
      "node/metrics_5\n",
      "\t ../tests/baselines/node_extracts2/node_extracts2.hdf5\n",
      "\n",
      "myparam40 vs myparam10\n",
      "\t ../tests/baselines/csv/my_csv_file.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Most Current\n",
    "    import sys\n",
    "    sys.path.append(\"/usr/gapps/pydv/current\")\n",
    "    import pydvpy\n",
    "except:\n",
    "    # PyPi or WEAVE Environment\n",
    "    from pydv import pydvpy\n",
    "\n",
    "\n",
    "curves = []\n",
    "\n",
    "# Ultra files output PyDV curve objects by default as seen in the beginning of this tutorial\n",
    "for ds in store.find():\n",
    "    for associated_ultra in ds.find(mime_type=\"ultra\"):\n",
    "        print(associated_ultra.uri)\n",
    "        curves.extend(dataset.open(Id=associated_ultra.id))\n",
    "\n",
    "        \n",
    "# Other data\n",
    "# hdf5\n",
    "data1 = dataset[\"node/metrics_5\"][:]\n",
    "print('HDF5')\n",
    "print(data1,'\\n\\n')\n",
    "curves.append(pydvpy.makecurve(x=data1[0],\n",
    "                               y=data1[1],\n",
    "                               name=\"node/metrics_5\",\n",
    "                               filename=\"../tests/baselines/node_extracts2/node_extracts2.hdf5\",\n",
    "                               record_id=dataset.id))\n",
    "                               \n",
    "# csv\n",
    "# The \"pandas/*\" mime types use the `pandas.read_*()` methods behind the scenes so you will get a `pandas.DataFrame()`\n",
    "data2 = dataset[[\"myparam10\", \"myparam40\"]][:]\n",
    "print('CSV')\n",
    "print(data2,'\\n\\n')\n",
    "curves.append(pydvpy.makecurve(x=data2[\"myparam10\"],\n",
    "                               y=data2[\"myparam40\"],\n",
    "                               name=\"myparam40 vs myparam10\",\n",
    "                               filename=\"../tests/baselines/csv/my_csv_file.csv\",\n",
    "                               record_id=dataset.id))\n",
    "\n",
    "\n",
    "print(curves)\n",
    "\n",
    "# Data is in curve.x and curve.y see curve.__dict__ for more info\n",
    "for curve in curves:\n",
    "    print(curve.name)\n",
    "    print(\"\\t\", curve.filename)\n",
    "    # print(curve.__dict__)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b87697-a9f3-4540-ade9-291eb7e494c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kosh-dev",
   "language": "python",
   "name": "kosh-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
